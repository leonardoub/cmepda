{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BRATS_nested_CV.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9SG15vFBZubxphyu02yuD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/cmepda/blob/master/BRATS_nested_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BthL8ZcBZ44G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "ad02e347-df7f-45ac-9dbd-80dc02422af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/gdrive/My Drive/BRATS/data_without_NAN_with_histologies.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.read_csv(dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znKJzW7bsbx",
        "colab_type": "code",
        "outputId": "0edea222-7af1-4b08-f15c-e1db872791b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>Date</th>\n",
              "      <th>VOLUME_ET</th>\n",
              "      <th>VOLUME_NET</th>\n",
              "      <th>VOLUME_ED</th>\n",
              "      <th>VOLUME_TC</th>\n",
              "      <th>VOLUME_WT</th>\n",
              "      <th>VOLUME_BRAIN</th>\n",
              "      <th>VOLUME_ET_OVER_NET</th>\n",
              "      <th>VOLUME_ET_OVER_ED</th>\n",
              "      <th>VOLUME_NET_OVER_ED</th>\n",
              "      <th>VOLUME_ET_over_TC</th>\n",
              "      <th>VOLUME_NET_over_TC</th>\n",
              "      <th>VOLUME_ED_over_TC</th>\n",
              "      <th>VOLUME_ET_OVER_WT</th>\n",
              "      <th>VOLUME_NET_OVER_WT</th>\n",
              "      <th>VOLUME_ED_OVER_WT</th>\n",
              "      <th>VOLUME_TC_OVER_WT</th>\n",
              "      <th>VOLUME_ET_OVER_BRAIN</th>\n",
              "      <th>VOLUME_NET_OVER_BRAIN</th>\n",
              "      <th>VOLUME_ED_over_BRAIN</th>\n",
              "      <th>VOLUME_TC_over_BRAIN</th>\n",
              "      <th>VOLUME_WT_OVER_BRAIN</th>\n",
              "      <th>DIST_Vent_TC</th>\n",
              "      <th>DIST_Vent_ED</th>\n",
              "      <th>INTENSITY_Mean_ET_T1Gd</th>\n",
              "      <th>INTENSITY_STD_ET_T1Gd</th>\n",
              "      <th>INTENSITY_Mean_ET_T1</th>\n",
              "      <th>INTENSITY_STD_ET_T1</th>\n",
              "      <th>INTENSITY_Mean_ET_T2</th>\n",
              "      <th>INTENSITY_STD_ET_T2</th>\n",
              "      <th>INTENSITY_Mean_ET_FLAIR</th>\n",
              "      <th>INTENSITY_STD_ET_FLAIR</th>\n",
              "      <th>INTENSITY_Mean_NET_T1Gd</th>\n",
              "      <th>INTENSITY_STD_NET_T1Gd</th>\n",
              "      <th>INTENSITY_Mean_NET_T1</th>\n",
              "      <th>INTENSITY_STD_NET_T1</th>\n",
              "      <th>INTENSITY_Mean_NET_T2</th>\n",
              "      <th>INTENSITY_STD_NET_T2</th>\n",
              "      <th>...</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Strength</th>\n",
              "      <th>TGM_p1</th>\n",
              "      <th>TGM_dw</th>\n",
              "      <th>TGM_Cog_X_1</th>\n",
              "      <th>TGM_Cog_Y_1</th>\n",
              "      <th>TGM_Cog_Z_1</th>\n",
              "      <th>TGM_T_1</th>\n",
              "      <th>Histology</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TCGA-02-0006</td>\n",
              "      <td>1996.08.23</td>\n",
              "      <td>1662</td>\n",
              "      <td>384</td>\n",
              "      <td>36268</td>\n",
              "      <td>2046</td>\n",
              "      <td>38314</td>\n",
              "      <td>1469432</td>\n",
              "      <td>4.328125</td>\n",
              "      <td>0.045826</td>\n",
              "      <td>0.010588</td>\n",
              "      <td>0.812320</td>\n",
              "      <td>0.187680</td>\n",
              "      <td>17.726300</td>\n",
              "      <td>0.043378</td>\n",
              "      <td>0.010022</td>\n",
              "      <td>0.946599</td>\n",
              "      <td>0.053401</td>\n",
              "      <td>0.001131</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.024682</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.026074</td>\n",
              "      <td>31.5903</td>\n",
              "      <td>2.7735</td>\n",
              "      <td>149.7977</td>\n",
              "      <td>10.4671</td>\n",
              "      <td>194.1422</td>\n",
              "      <td>15.1037</td>\n",
              "      <td>154.9225</td>\n",
              "      <td>43.4709</td>\n",
              "      <td>220.5894</td>\n",
              "      <td>30.2917</td>\n",
              "      <td>137.8881</td>\n",
              "      <td>6.3820</td>\n",
              "      <td>183.6933</td>\n",
              "      <td>14.8846</td>\n",
              "      <td>161.1005</td>\n",
              "      <td>35.8591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.86315</td>\n",
              "      <td>1479.9762</td>\n",
              "      <td>1.10870</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>0.40937</td>\n",
              "      <td>1.47070</td>\n",
              "      <td>2992.2698</td>\n",
              "      <td>0.71642</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.28977</td>\n",
              "      <td>1.8815</td>\n",
              "      <td>1872.0528</td>\n",
              "      <td>0.75986</td>\n",
              "      <td>0.026040</td>\n",
              "      <td>0.37869</td>\n",
              "      <td>0.060929</td>\n",
              "      <td>1675.0041</td>\n",
              "      <td>14.11380</td>\n",
              "      <td>0.044156</td>\n",
              "      <td>0.41942</td>\n",
              "      <td>0.026740</td>\n",
              "      <td>2536.7559</td>\n",
              "      <td>43.31290</td>\n",
              "      <td>0.036634</td>\n",
              "      <td>0.50304</td>\n",
              "      <td>0.024264</td>\n",
              "      <td>3593.3279</td>\n",
              "      <td>43.67590</td>\n",
              "      <td>0.057204</td>\n",
              "      <td>0.33980</td>\n",
              "      <td>0.021897</td>\n",
              "      <td>2203.2034</td>\n",
              "      <td>61.32930</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.178609</td>\n",
              "      <td>0.096256</td>\n",
              "      <td>0.052741</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TCGA-02-0009</td>\n",
              "      <td>1997.06.14</td>\n",
              "      <td>4362</td>\n",
              "      <td>4349</td>\n",
              "      <td>15723</td>\n",
              "      <td>8711</td>\n",
              "      <td>24434</td>\n",
              "      <td>1295721</td>\n",
              "      <td>1.002989</td>\n",
              "      <td>0.277428</td>\n",
              "      <td>0.276601</td>\n",
              "      <td>0.500750</td>\n",
              "      <td>0.499250</td>\n",
              "      <td>1.805000</td>\n",
              "      <td>0.178522</td>\n",
              "      <td>0.177990</td>\n",
              "      <td>0.643489</td>\n",
              "      <td>0.356511</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.003356</td>\n",
              "      <td>0.012135</td>\n",
              "      <td>0.006723</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>9.2443</td>\n",
              "      <td>3.0207</td>\n",
              "      <td>165.4345</td>\n",
              "      <td>6.4047</td>\n",
              "      <td>201.2400</td>\n",
              "      <td>13.4733</td>\n",
              "      <td>113.1601</td>\n",
              "      <td>10.1373</td>\n",
              "      <td>210.1810</td>\n",
              "      <td>15.9543</td>\n",
              "      <td>152.6013</td>\n",
              "      <td>4.2360</td>\n",
              "      <td>188.0607</td>\n",
              "      <td>11.1316</td>\n",
              "      <td>116.8538</td>\n",
              "      <td>10.0992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.40004</td>\n",
              "      <td>2378.9184</td>\n",
              "      <td>2.54730</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.70926</td>\n",
              "      <td>0.78063</td>\n",
              "      <td>5719.2847</td>\n",
              "      <td>1.29980</td>\n",
              "      <td>0.000882</td>\n",
              "      <td>0.48919</td>\n",
              "      <td>1.8243</td>\n",
              "      <td>2954.8148</td>\n",
              "      <td>0.77199</td>\n",
              "      <td>0.002254</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>1.223600</td>\n",
              "      <td>539.3057</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.005712</td>\n",
              "      <td>0.20995</td>\n",
              "      <td>0.315580</td>\n",
              "      <td>967.7845</td>\n",
              "      <td>3.74440</td>\n",
              "      <td>0.003790</td>\n",
              "      <td>0.36163</td>\n",
              "      <td>0.271420</td>\n",
              "      <td>1996.1440</td>\n",
              "      <td>2.77050</td>\n",
              "      <td>0.004966</td>\n",
              "      <td>0.28715</td>\n",
              "      <td>0.189980</td>\n",
              "      <td>1440.4285</td>\n",
              "      <td>3.59990</td>\n",
              "      <td>3.31250</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.077618</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.094336</td>\n",
              "      <td>91.47360</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TCGA-02-0011</td>\n",
              "      <td>1998.02.01</td>\n",
              "      <td>33404</td>\n",
              "      <td>48612</td>\n",
              "      <td>45798</td>\n",
              "      <td>82016</td>\n",
              "      <td>127814</td>\n",
              "      <td>1425843</td>\n",
              "      <td>0.687155</td>\n",
              "      <td>0.729377</td>\n",
              "      <td>1.061444</td>\n",
              "      <td>0.407290</td>\n",
              "      <td>0.592710</td>\n",
              "      <td>0.558400</td>\n",
              "      <td>0.261349</td>\n",
              "      <td>0.380334</td>\n",
              "      <td>0.358318</td>\n",
              "      <td>0.641682</td>\n",
              "      <td>0.023428</td>\n",
              "      <td>0.034094</td>\n",
              "      <td>0.032120</td>\n",
              "      <td>0.057521</td>\n",
              "      <td>0.089641</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>186.3385</td>\n",
              "      <td>17.6126</td>\n",
              "      <td>188.2019</td>\n",
              "      <td>23.5195</td>\n",
              "      <td>172.8969</td>\n",
              "      <td>32.7401</td>\n",
              "      <td>167.1395</td>\n",
              "      <td>34.1684</td>\n",
              "      <td>149.0643</td>\n",
              "      <td>12.9090</td>\n",
              "      <td>158.4197</td>\n",
              "      <td>15.2632</td>\n",
              "      <td>197.4966</td>\n",
              "      <td>27.1781</td>\n",
              "      <td>...</td>\n",
              "      <td>1.51780</td>\n",
              "      <td>1750.3404</td>\n",
              "      <td>0.56482</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.59301</td>\n",
              "      <td>1.81810</td>\n",
              "      <td>4990.3388</td>\n",
              "      <td>0.54747</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.59184</td>\n",
              "      <td>2.4243</td>\n",
              "      <td>4703.9458</td>\n",
              "      <td>0.41937</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.37863</td>\n",
              "      <td>1.957500</td>\n",
              "      <td>2509.3979</td>\n",
              "      <td>0.42842</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>0.19849</td>\n",
              "      <td>1.395800</td>\n",
              "      <td>1322.6082</td>\n",
              "      <td>0.74730</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>0.31856</td>\n",
              "      <td>1.144300</td>\n",
              "      <td>2517.8629</td>\n",
              "      <td>0.84294</td>\n",
              "      <td>0.000794</td>\n",
              "      <td>0.17961</td>\n",
              "      <td>1.068800</td>\n",
              "      <td>1147.5177</td>\n",
              "      <td>0.80480</td>\n",
              "      <td>5.78125</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.132283</td>\n",
              "      <td>0.116006</td>\n",
              "      <td>0.096035</td>\n",
              "      <td>272.42900</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TCGA-02-0027</td>\n",
              "      <td>1999.03.28</td>\n",
              "      <td>12114</td>\n",
              "      <td>7587</td>\n",
              "      <td>34086</td>\n",
              "      <td>19701</td>\n",
              "      <td>53787</td>\n",
              "      <td>1403429</td>\n",
              "      <td>1.596679</td>\n",
              "      <td>0.355395</td>\n",
              "      <td>0.222584</td>\n",
              "      <td>0.614890</td>\n",
              "      <td>0.385110</td>\n",
              "      <td>1.730200</td>\n",
              "      <td>0.225222</td>\n",
              "      <td>0.141056</td>\n",
              "      <td>0.633722</td>\n",
              "      <td>0.366278</td>\n",
              "      <td>0.008632</td>\n",
              "      <td>0.005406</td>\n",
              "      <td>0.024288</td>\n",
              "      <td>0.014038</td>\n",
              "      <td>0.038325</td>\n",
              "      <td>1.0331</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>178.6925</td>\n",
              "      <td>23.1751</td>\n",
              "      <td>199.7626</td>\n",
              "      <td>27.0047</td>\n",
              "      <td>157.0192</td>\n",
              "      <td>25.6793</td>\n",
              "      <td>173.6525</td>\n",
              "      <td>26.3596</td>\n",
              "      <td>120.3726</td>\n",
              "      <td>17.5926</td>\n",
              "      <td>199.5765</td>\n",
              "      <td>25.3652</td>\n",
              "      <td>194.2708</td>\n",
              "      <td>24.5411</td>\n",
              "      <td>...</td>\n",
              "      <td>0.78104</td>\n",
              "      <td>1870.7630</td>\n",
              "      <td>1.37070</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.65247</td>\n",
              "      <td>1.46450</td>\n",
              "      <td>5625.0240</td>\n",
              "      <td>0.66930</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.66446</td>\n",
              "      <td>1.5863</td>\n",
              "      <td>5585.3565</td>\n",
              "      <td>0.60995</td>\n",
              "      <td>0.001456</td>\n",
              "      <td>0.89121</td>\n",
              "      <td>0.485160</td>\n",
              "      <td>7372.7070</td>\n",
              "      <td>2.03510</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.23036</td>\n",
              "      <td>0.143560</td>\n",
              "      <td>1722.6804</td>\n",
              "      <td>6.94490</td>\n",
              "      <td>0.002126</td>\n",
              "      <td>0.54383</td>\n",
              "      <td>0.379490</td>\n",
              "      <td>3698.6228</td>\n",
              "      <td>2.31820</td>\n",
              "      <td>0.003284</td>\n",
              "      <td>0.41179</td>\n",
              "      <td>0.206600</td>\n",
              "      <td>3320.1690</td>\n",
              "      <td>4.73360</td>\n",
              "      <td>3.87500</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.100415</td>\n",
              "      <td>0.088249</td>\n",
              "      <td>0.096470</td>\n",
              "      <td>128.46800</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TCGA-02-0033</td>\n",
              "      <td>1997.05.26</td>\n",
              "      <td>34538</td>\n",
              "      <td>7137</td>\n",
              "      <td>65653</td>\n",
              "      <td>41675</td>\n",
              "      <td>107328</td>\n",
              "      <td>1365237</td>\n",
              "      <td>4.839288</td>\n",
              "      <td>0.526069</td>\n",
              "      <td>0.108708</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.171250</td>\n",
              "      <td>1.575400</td>\n",
              "      <td>0.321799</td>\n",
              "      <td>0.066497</td>\n",
              "      <td>0.611704</td>\n",
              "      <td>0.388296</td>\n",
              "      <td>0.025298</td>\n",
              "      <td>0.005228</td>\n",
              "      <td>0.048089</td>\n",
              "      <td>0.030526</td>\n",
              "      <td>0.078615</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>172.4109</td>\n",
              "      <td>27.5731</td>\n",
              "      <td>121.4969</td>\n",
              "      <td>10.3061</td>\n",
              "      <td>148.9331</td>\n",
              "      <td>27.8493</td>\n",
              "      <td>159.0135</td>\n",
              "      <td>23.9666</td>\n",
              "      <td>116.9944</td>\n",
              "      <td>8.2358</td>\n",
              "      <td>117.7009</td>\n",
              "      <td>9.9957</td>\n",
              "      <td>139.4320</td>\n",
              "      <td>34.3293</td>\n",
              "      <td>...</td>\n",
              "      <td>1.80660</td>\n",
              "      <td>1959.4667</td>\n",
              "      <td>0.56070</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.48428</td>\n",
              "      <td>2.18490</td>\n",
              "      <td>4083.7014</td>\n",
              "      <td>0.46492</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.40305</td>\n",
              "      <td>1.8266</td>\n",
              "      <td>3592.2992</td>\n",
              "      <td>0.56135</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>0.42666</td>\n",
              "      <td>0.950220</td>\n",
              "      <td>2072.5900</td>\n",
              "      <td>1.17490</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.14562</td>\n",
              "      <td>0.713820</td>\n",
              "      <td>538.8446</td>\n",
              "      <td>1.14360</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>0.47817</td>\n",
              "      <td>0.555670</td>\n",
              "      <td>3020.3680</td>\n",
              "      <td>1.90570</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.31043</td>\n",
              "      <td>0.413750</td>\n",
              "      <td>1834.1052</td>\n",
              "      <td>2.45320</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.725000e-08</td>\n",
              "      <td>0.106184</td>\n",
              "      <td>0.131952</td>\n",
              "      <td>0.096894</td>\n",
              "      <td>240.77800</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>TCGA-HT-7694</td>\n",
              "      <td>1995.04.04</td>\n",
              "      <td>1036</td>\n",
              "      <td>189152</td>\n",
              "      <td>171595</td>\n",
              "      <td>190188</td>\n",
              "      <td>361783</td>\n",
              "      <td>1611350</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.006037</td>\n",
              "      <td>1.102317</td>\n",
              "      <td>0.005447</td>\n",
              "      <td>0.994550</td>\n",
              "      <td>0.902240</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>0.522833</td>\n",
              "      <td>0.474304</td>\n",
              "      <td>0.525696</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.117387</td>\n",
              "      <td>0.106490</td>\n",
              "      <td>0.118030</td>\n",
              "      <td>0.224522</td>\n",
              "      <td>1.5561</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>130.5401</td>\n",
              "      <td>10.8604</td>\n",
              "      <td>158.2426</td>\n",
              "      <td>5.1363</td>\n",
              "      <td>160.5840</td>\n",
              "      <td>13.3742</td>\n",
              "      <td>196.0449</td>\n",
              "      <td>12.1558</td>\n",
              "      <td>85.7372</td>\n",
              "      <td>14.1637</td>\n",
              "      <td>135.7749</td>\n",
              "      <td>12.9578</td>\n",
              "      <td>172.2660</td>\n",
              "      <td>25.9874</td>\n",
              "      <td>...</td>\n",
              "      <td>3.89200</td>\n",
              "      <td>1050.8760</td>\n",
              "      <td>0.26584</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.28803</td>\n",
              "      <td>3.76680</td>\n",
              "      <td>2246.2262</td>\n",
              "      <td>0.26343</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.32326</td>\n",
              "      <td>3.7144</td>\n",
              "      <td>2862.7663</td>\n",
              "      <td>0.26864</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.39033</td>\n",
              "      <td>4.843700</td>\n",
              "      <td>3149.1624</td>\n",
              "      <td>0.20185</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.17338</td>\n",
              "      <td>4.129200</td>\n",
              "      <td>1181.3019</td>\n",
              "      <td>0.23864</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.33542</td>\n",
              "      <td>4.444300</td>\n",
              "      <td>2706.6360</td>\n",
              "      <td>0.22259</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.25558</td>\n",
              "      <td>3.698700</td>\n",
              "      <td>2033.8540</td>\n",
              "      <td>0.26785</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.070503</td>\n",
              "      <td>0.090456</td>\n",
              "      <td>719.23800</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>142</td>\n",
              "      <td>TCGA-HT-8018</td>\n",
              "      <td>1997.04.11</td>\n",
              "      <td>2093</td>\n",
              "      <td>8685</td>\n",
              "      <td>39142</td>\n",
              "      <td>10778</td>\n",
              "      <td>49920</td>\n",
              "      <td>1493262</td>\n",
              "      <td>0.240990</td>\n",
              "      <td>0.053472</td>\n",
              "      <td>0.221884</td>\n",
              "      <td>0.194190</td>\n",
              "      <td>0.805810</td>\n",
              "      <td>3.631700</td>\n",
              "      <td>0.041927</td>\n",
              "      <td>0.173978</td>\n",
              "      <td>0.784095</td>\n",
              "      <td>0.215905</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.005816</td>\n",
              "      <td>0.026212</td>\n",
              "      <td>0.007218</td>\n",
              "      <td>0.033430</td>\n",
              "      <td>7.8703</td>\n",
              "      <td>1.2296</td>\n",
              "      <td>122.5820</td>\n",
              "      <td>24.4042</td>\n",
              "      <td>90.7803</td>\n",
              "      <td>9.1876</td>\n",
              "      <td>189.3704</td>\n",
              "      <td>11.4401</td>\n",
              "      <td>176.2758</td>\n",
              "      <td>14.7584</td>\n",
              "      <td>81.0780</td>\n",
              "      <td>10.4078</td>\n",
              "      <td>88.8951</td>\n",
              "      <td>9.1065</td>\n",
              "      <td>189.3633</td>\n",
              "      <td>14.4565</td>\n",
              "      <td>...</td>\n",
              "      <td>0.56593</td>\n",
              "      <td>1255.6524</td>\n",
              "      <td>1.74930</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.48939</td>\n",
              "      <td>1.56420</td>\n",
              "      <td>3817.4564</td>\n",
              "      <td>0.62083</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.38268</td>\n",
              "      <td>1.2343</td>\n",
              "      <td>3032.0641</td>\n",
              "      <td>0.77990</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.37981</td>\n",
              "      <td>0.402750</td>\n",
              "      <td>2605.8492</td>\n",
              "      <td>2.57200</td>\n",
              "      <td>0.004937</td>\n",
              "      <td>0.14295</td>\n",
              "      <td>0.201910</td>\n",
              "      <td>882.1737</td>\n",
              "      <td>4.27000</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.37387</td>\n",
              "      <td>0.370130</td>\n",
              "      <td>2336.3329</td>\n",
              "      <td>2.22420</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>0.22536</td>\n",
              "      <td>0.200950</td>\n",
              "      <td>1446.4163</td>\n",
              "      <td>3.99730</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.168857</td>\n",
              "      <td>0.120586</td>\n",
              "      <td>0.054307</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>TCGA-HT-8111</td>\n",
              "      <td>1998.03.30</td>\n",
              "      <td>1929</td>\n",
              "      <td>437</td>\n",
              "      <td>54079</td>\n",
              "      <td>2366</td>\n",
              "      <td>56445</td>\n",
              "      <td>1821157</td>\n",
              "      <td>4.414188</td>\n",
              "      <td>0.035670</td>\n",
              "      <td>0.008081</td>\n",
              "      <td>0.815300</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>22.856700</td>\n",
              "      <td>0.034175</td>\n",
              "      <td>0.007742</td>\n",
              "      <td>0.958083</td>\n",
              "      <td>0.041917</td>\n",
              "      <td>0.001059</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.029695</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.030994</td>\n",
              "      <td>19.5113</td>\n",
              "      <td>2.7359</td>\n",
              "      <td>114.8266</td>\n",
              "      <td>16.4708</td>\n",
              "      <td>88.3256</td>\n",
              "      <td>5.7475</td>\n",
              "      <td>135.0452</td>\n",
              "      <td>10.8131</td>\n",
              "      <td>153.4996</td>\n",
              "      <td>7.2622</td>\n",
              "      <td>84.3018</td>\n",
              "      <td>8.0198</td>\n",
              "      <td>88.9795</td>\n",
              "      <td>5.3935</td>\n",
              "      <td>131.7430</td>\n",
              "      <td>11.2399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.80255</td>\n",
              "      <td>863.0606</td>\n",
              "      <td>1.39180</td>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.34568</td>\n",
              "      <td>1.24340</td>\n",
              "      <td>2832.2946</td>\n",
              "      <td>0.78981</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.32099</td>\n",
              "      <td>1.6823</td>\n",
              "      <td>2470.0227</td>\n",
              "      <td>0.55317</td>\n",
              "      <td>0.017196</td>\n",
              "      <td>0.86464</td>\n",
              "      <td>0.061184</td>\n",
              "      <td>5330.9937</td>\n",
              "      <td>14.26100</td>\n",
              "      <td>0.053508</td>\n",
              "      <td>0.17277</td>\n",
              "      <td>0.029481</td>\n",
              "      <td>879.6829</td>\n",
              "      <td>34.79070</td>\n",
              "      <td>0.036952</td>\n",
              "      <td>0.26426</td>\n",
              "      <td>0.039567</td>\n",
              "      <td>1317.6443</td>\n",
              "      <td>22.83400</td>\n",
              "      <td>0.052586</td>\n",
              "      <td>0.20996</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>803.8863</td>\n",
              "      <td>27.48750</td>\n",
              "      <td>1.96875</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.148932</td>\n",
              "      <td>0.073453</td>\n",
              "      <td>0.126712</td>\n",
              "      <td>7.06744</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>144</td>\n",
              "      <td>TCGA-HT-8114</td>\n",
              "      <td>1998.10.30</td>\n",
              "      <td>8755</td>\n",
              "      <td>168606</td>\n",
              "      <td>11325</td>\n",
              "      <td>177361</td>\n",
              "      <td>188686</td>\n",
              "      <td>1693971</td>\n",
              "      <td>0.051926</td>\n",
              "      <td>0.773068</td>\n",
              "      <td>14.887947</td>\n",
              "      <td>0.049363</td>\n",
              "      <td>0.950640</td>\n",
              "      <td>0.063853</td>\n",
              "      <td>0.046400</td>\n",
              "      <td>0.893580</td>\n",
              "      <td>0.060020</td>\n",
              "      <td>0.939980</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>0.099533</td>\n",
              "      <td>0.006686</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>0.111387</td>\n",
              "      <td>2.2261</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>92.3248</td>\n",
              "      <td>10.9722</td>\n",
              "      <td>96.4461</td>\n",
              "      <td>7.0449</td>\n",
              "      <td>120.4493</td>\n",
              "      <td>18.3507</td>\n",
              "      <td>168.2873</td>\n",
              "      <td>13.7084</td>\n",
              "      <td>76.0316</td>\n",
              "      <td>15.3670</td>\n",
              "      <td>98.1388</td>\n",
              "      <td>11.9586</td>\n",
              "      <td>127.2041</td>\n",
              "      <td>26.8906</td>\n",
              "      <td>...</td>\n",
              "      <td>0.31348</td>\n",
              "      <td>1119.2382</td>\n",
              "      <td>2.66250</td>\n",
              "      <td>0.001288</td>\n",
              "      <td>0.68191</td>\n",
              "      <td>0.60512</td>\n",
              "      <td>5246.9633</td>\n",
              "      <td>1.69490</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>1.15310</td>\n",
              "      <td>3.3277</td>\n",
              "      <td>6027.3574</td>\n",
              "      <td>0.55024</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.37937</td>\n",
              "      <td>4.644300</td>\n",
              "      <td>2996.8473</td>\n",
              "      <td>0.21714</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.15073</td>\n",
              "      <td>3.012000</td>\n",
              "      <td>1054.1171</td>\n",
              "      <td>0.36431</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.30578</td>\n",
              "      <td>3.346700</td>\n",
              "      <td>2515.2461</td>\n",
              "      <td>0.28794</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.25687</td>\n",
              "      <td>2.991600</td>\n",
              "      <td>2055.4227</td>\n",
              "      <td>0.30710</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.168182</td>\n",
              "      <td>0.167317</td>\n",
              "      <td>0.107433</td>\n",
              "      <td>15.52240</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145</td>\n",
              "      <td>TCGA-HT-8563</td>\n",
              "      <td>1998.12.09</td>\n",
              "      <td>11757</td>\n",
              "      <td>1012</td>\n",
              "      <td>138755</td>\n",
              "      <td>12769</td>\n",
              "      <td>151524</td>\n",
              "      <td>1605161</td>\n",
              "      <td>11.617589</td>\n",
              "      <td>0.084732</td>\n",
              "      <td>0.007293</td>\n",
              "      <td>0.920750</td>\n",
              "      <td>0.079254</td>\n",
              "      <td>10.866600</td>\n",
              "      <td>0.077592</td>\n",
              "      <td>0.006679</td>\n",
              "      <td>0.915730</td>\n",
              "      <td>0.084270</td>\n",
              "      <td>0.007324</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.086443</td>\n",
              "      <td>0.007955</td>\n",
              "      <td>0.094398</td>\n",
              "      <td>6.3847</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>154.6832</td>\n",
              "      <td>49.8662</td>\n",
              "      <td>103.6185</td>\n",
              "      <td>5.3827</td>\n",
              "      <td>108.7191</td>\n",
              "      <td>12.4944</td>\n",
              "      <td>168.1385</td>\n",
              "      <td>15.0086</td>\n",
              "      <td>87.1151</td>\n",
              "      <td>9.9561</td>\n",
              "      <td>98.4603</td>\n",
              "      <td>3.5746</td>\n",
              "      <td>112.2253</td>\n",
              "      <td>7.8119</td>\n",
              "      <td>...</td>\n",
              "      <td>3.98400</td>\n",
              "      <td>724.9046</td>\n",
              "      <td>0.26198</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.37976</td>\n",
              "      <td>3.41390</td>\n",
              "      <td>3293.8152</td>\n",
              "      <td>0.28105</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.29310</td>\n",
              "      <td>2.6220</td>\n",
              "      <td>2582.0410</td>\n",
              "      <td>0.36389</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>1.27720</td>\n",
              "      <td>0.102260</td>\n",
              "      <td>10178.0572</td>\n",
              "      <td>9.39250</td>\n",
              "      <td>0.015050</td>\n",
              "      <td>0.23963</td>\n",
              "      <td>0.220530</td>\n",
              "      <td>731.4574</td>\n",
              "      <td>5.35820</td>\n",
              "      <td>0.015620</td>\n",
              "      <td>0.40833</td>\n",
              "      <td>0.076820</td>\n",
              "      <td>2324.7276</td>\n",
              "      <td>12.31230</td>\n",
              "      <td>0.028514</td>\n",
              "      <td>0.21704</td>\n",
              "      <td>0.065338</td>\n",
              "      <td>1056.9519</td>\n",
              "      <td>20.27440</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>3.213120e-07</td>\n",
              "      <td>0.072868</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.069101</td>\n",
              "      <td>7.62280</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows × 708 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0            ID        Date  ...  TGM_Cog_Z_1    TGM_T_1  Histology\n",
              "0             0  TCGA-02-0006  1996.08.23  ...     0.052741    2.00000        GBM\n",
              "1             1  TCGA-02-0009  1997.06.14  ...     0.094336   91.47360        GBM\n",
              "2             2  TCGA-02-0011  1998.02.01  ...     0.096035  272.42900        GBM\n",
              "3             3  TCGA-02-0027  1999.03.28  ...     0.096470  128.46800        GBM\n",
              "4             4  TCGA-02-0033  1997.05.26  ...     0.096894  240.77800        GBM\n",
              "..          ...           ...         ...  ...          ...        ...        ...\n",
              "141         141  TCGA-HT-7694  1995.04.04  ...     0.090456  719.23800        LGG\n",
              "142         142  TCGA-HT-8018  1997.04.11  ...     0.054307    2.00000        LGG\n",
              "143         143  TCGA-HT-8111  1998.03.30  ...     0.126712    7.06744        LGG\n",
              "144         144  TCGA-HT-8114  1998.10.30  ...     0.107433   15.52240        LGG\n",
              "145         145  TCGA-HT-8563  1998.12.09  ...     0.069101    7.62280        LGG\n",
              "\n",
              "[146 rows x 708 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZviWnrbyAT",
        "colab_type": "code",
        "outputId": "e3ca9e9a-8e9c-46fc-e9c5-66f88cdb122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "df_data.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ID', 'Date', 'VOLUME_ET', 'VOLUME_NET', 'VOLUME_ED',\n",
              "       'VOLUME_TC', 'VOLUME_WT', 'VOLUME_BRAIN', 'VOLUME_ET_OVER_NET',\n",
              "       ...\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Busyness',\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Complexity',\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Strength', 'TGM_p1', 'TGM_dw', 'TGM_Cog_X_1',\n",
              "       'TGM_Cog_Y_1', 'TGM_Cog_Z_1', 'TGM_T_1', 'Histology'],\n",
              "      dtype='object', length=708)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df_data.drop(['Histology', 'Unnamed: 0', 'ID', 'Date'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df_data.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b_lnjdLcWEj",
        "colab_type": "text"
      },
      "source": [
        "#Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hG99bXOxf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2d80867a-425b-425c-d592-d5e513b25a73"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV,KFold,cross_val_predict,cross_val_score,StratifiedKFold\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYvW7PB3Rqly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vettorizzare i label\n",
        "encoder = LabelEncoder()\n",
        "labels_encoded = encoder.fit_transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmG6Fx2eR-3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scalers\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "scalers_to_test = [StandardScaler(), RobustScaler(), MinMaxScaler(), None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcDzZhRSSCLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Designate distributions to sample hyperparameters from \n",
        "n_tree = [10, 50, 100, 150]\n",
        "n_features_to_test = [0.9]\n",
        "depth = [10, None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JigjLrG-Vp0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose cross-validation techniques for the inner and outer loops,\n",
        "# independently of the dataset.\n",
        "# E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wTioNOISOm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RandomForestClassifier\n",
        "steps = [('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state=503))]\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "parameteres = [{'scaler':[StandardScaler()], \n",
        "                'clf__n_estimators':list(n_tree), 'clf__criterion':['gini', 'entropy'], \n",
        "                'clf__max_depth':depth, 'clf__min_samples_split':[2, 5], \n",
        "                'clf__min_samples_leaf':[2, 4], 'clf__class_weight':[None, 'balanced']}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnj6__VFVbc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=inner_cv, n_jobs=-1, scoring='roc_auc', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOy1QLkWZNMv",
        "colab_type": "code",
        "outputId": "b5628418-eab0-43b6-9ef2-73ac03a55b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Nested CV with parameter optimization\n",
        "nested_score = cross_val_score(grid, X=data, y=labels_encoded, cv=outer_cv)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-e8e2f08bb3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKW1rFsNaR2n",
        "colab_type": "text"
      },
      "source": [
        "In questo modo non riesco a sapere quali sono i best HP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbZgiLfkaRe_",
        "colab_type": "code",
        "outputId": "735720fb-95e1-4289-fb72-e700f7a3f756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nested_score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.81176471, 0.90784314, 0.88865546])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z5lfT0qXkIh",
        "colab_type": "text"
      },
      "source": [
        "questi dovrebbero essere i risultati del ciclo esterno di CV, ma con quali hp???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oT1Ld2cXZjv",
        "colab_type": "text"
      },
      "source": [
        "#ANOTHER WAY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3CYwBpIclrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "dba3af78-3203-4401-9ab9-18e25a17efb0"
      },
      "source": [
        "train_index"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,\n",
              "        15,  16,  17,  18,  19,  22,  23,  24,  25,  26,  29,  30,  31,\n",
              "        34,  35,  36,  37,  38,  39,  40,  42,  43,  44,  45,  47,  48,\n",
              "        49,  50,  52,  53,  54,  57,  58,  59,  61,  63,  65,  66,  68,\n",
              "        70,  71,  73,  74,  76,  78,  79,  84,  87,  90,  91,  94,  95,\n",
              "        97,  99, 101, 102, 104, 106, 109, 110, 111, 112, 114, 115, 116,\n",
              "       117, 118, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133,\n",
              "       134, 137, 138, 141, 142, 143])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiZqSx_Yat3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMV4uK0Akehf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfObj.iloc[[2 ,0 ] , : ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSnfwj50liqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "cce7baaf-3dc3-4ecd-d178-2b84ec3cc9d0"
      },
      "source": [
        "train_index"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,\n",
              "        15,  16,  17,  18,  19,  22,  23,  24,  25,  26,  29,  30,  31,\n",
              "        34,  35,  36,  37,  38,  39,  40,  42,  43,  44,  45,  47,  48,\n",
              "        49,  50,  52,  53,  54,  57,  58,  59,  61,  63,  65,  66,  68,\n",
              "        70,  71,  73,  74,  76,  78,  79,  84,  87,  90,  91,  94,  95,\n",
              "        97,  99, 101, 102, 104, 106, 109, 110, 111, 112, 114, 115, 116,\n",
              "       117, 118, 120, 121, 122, 125, 127, 128, 129, 130, 131, 132, 133,\n",
              "       134, 137, 138, 141, 142, 143])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F44Ru3-xlytR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9433228b-d8be-4855-b485-48d612dfe0c0"
      },
      "source": [
        "labels_encoded[train_index]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVfX7QlJXrtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "dca9c0da-228b-4553-8c58-c9c8897b317b"
      },
      "source": [
        "outer_loop_roc_auc_scores = []\n",
        "inner_loop_won_params = []\n",
        "inner_loop_roc_auc_scores = []\n",
        "D = {}\n",
        "i = 0\n",
        "\n",
        "# Looping through the outer loop, feeding each training set into a GSCV as the inner loop\n",
        "for train_index, test_index in outer_cv.split(data, labels_encoded):\n",
        "    \n",
        "    i+=1\n",
        "\n",
        "    GSCV = GridSearchCV(pipeline, param_grid=parameteres, cv=inner_cv, n_jobs=-1, scoring='roc_auc', verbose=1)\n",
        "    \n",
        "    # GSCV is looping through the training data to find the best parameters. This is the inner loop\n",
        "    GSCV.fit(data.iloc[train_index, :], labels_encoded[train_index])\n",
        "    \n",
        "    # The best hyper parameters from GSCV is now being tested on the unseen outer loop test data.\n",
        "    pred = GSCV.predict(data.iloc[test_index, :])\n",
        "    \n",
        "\n",
        "    #conviene far uscire i best_estimators in qualche modo\n",
        "    #The most important 10 features for the best estimator\n",
        "    #features_list =  sorted(zip(rank_features, data.columns), reverse=True)[:10]\n",
        "\n",
        "    #D.update({i : 23})\n",
        "\n",
        "    # Appending the \"winning\" hyper parameters and their associated accuracy score\n",
        "    inner_loop_won_params.append(GSCV.best_params_)\n",
        "    outer_loop_roc_auc_scores.append(roc_auc_score(labels_encoded[test_index], pred))\n",
        "    inner_loop_roc_auc_scores.append(GSCV.best_score_)\n",
        "\n",
        "for i in zip(inner_loop_won_params, outer_loop_roc_auc_scores, inner_loop_roc_auc_scores):\n",
        "    print(i)\n",
        "\n",
        "#print('Mean of outer loop accuracy score:' np.mean(outer_loop_roc_auc_scores))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   23.7s\n",
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   46.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   44.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    9.5s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "({'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__n_estimators': 150, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.7852941176470588, 0.9476796955057823)\n",
            "({'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 150, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.9, 0.899026496852584)\n",
            "({'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 100, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.8550420168067226, 0.9661396574440054)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   44.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2bFP40snboT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3df50c8d-1ac1-4273-af5f-f9b82f1a5598"
      },
      "source": [
        "inner_loop_roc_auc_scores"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9476796955057823, 0.899026496852584, 0.9661396574440054]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCtgiIUpneJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "027f667c-e76a-413d-efb7-c72b6db3d1fa"
      },
      "source": [
        "outer_loop_roc_auc_scores"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7852941176470588, 0.9, 0.8550420168067226]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYzH5o8atLSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank_features = GSCV.best_estimator_.named_steps[\"clf\"].feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPCzpd9Kx_SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fcf7c7c-b8c5-4638-a53e-31345fcdae2e"
      },
      "source": [
        "rank_features"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.18994501e-02, 0.00000000e+00, 0.00000000e+00, 1.40253842e-03,\n",
              "       0.00000000e+00, 1.00706678e-03, 8.79950020e-03, 1.34298453e-02,\n",
              "       0.00000000e+00, 1.01936147e-03, 5.50684222e-03, 0.00000000e+00,\n",
              "       3.40046590e-02, 4.59768202e-03, 1.85830321e-03, 1.98521201e-03,\n",
              "       1.09124774e-02, 3.40277778e-03, 0.00000000e+00, 1.66962165e-03,\n",
              "       5.63302809e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.41970641e-04, 0.00000000e+00, 5.39639614e-05,\n",
              "       3.10964476e-03, 8.69565217e-05, 0.00000000e+00, 6.88388284e-04,\n",
              "       9.41785018e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       7.12597700e-03, 8.85183902e-04, 0.00000000e+00, 9.44034812e-04,\n",
              "       4.65326605e-03, 9.34753194e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.45267017e-04, 0.00000000e+00, 9.26519962e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.00338666e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.15015208e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.02748777e-03, 0.00000000e+00, 1.25450785e-03,\n",
              "       0.00000000e+00, 1.95605196e-03, 7.23606363e-04, 1.78352005e-03,\n",
              "       0.00000000e+00, 2.41768370e-04, 6.71403409e-04, 0.00000000e+00,\n",
              "       1.04341994e-03, 8.41020163e-04, 9.58198413e-05, 7.95899747e-04,\n",
              "       1.18775366e-03, 1.04040634e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.33826202e-03, 9.75421671e-05, 8.73194812e-04,\n",
              "       0.00000000e+00, 1.00216415e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.48776964e-04, 0.00000000e+00, 1.88067342e-03, 8.52898734e-04,\n",
              "       1.03125130e-03, 1.71239771e-03, 4.60866352e-04, 0.00000000e+00,\n",
              "       1.03435860e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.36912774e-03, 0.00000000e+00, 1.59219738e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.58070145e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.40894097e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 8.93806032e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.06197410e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.93937612e-03,\n",
              "       0.00000000e+00, 6.14300871e-04, 0.00000000e+00, 2.07703859e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.46042999e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.70553629e-04, 2.30935604e-03, 4.58849082e-04,\n",
              "       6.29144049e-04, 0.00000000e+00, 4.76941993e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 8.88016458e-05, 4.60584482e-04, 4.25233470e-04,\n",
              "       0.00000000e+00, 3.46092859e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.90104254e-05, 9.50564569e-04, 1.01466289e-03, 1.06730195e-03,\n",
              "       8.62027684e-05, 9.07054123e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.58440220e-03, 7.85245803e-05, 3.43554992e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.80335162e-04, 8.53843991e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.59746818e-03, 0.00000000e+00, 6.20860927e-05,\n",
              "       4.72689873e-04, 0.00000000e+00, 3.23027366e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 7.54988336e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.21773450e-04, 0.00000000e+00, 2.23493413e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.87581028e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.58188988e-03, 1.08023803e-03, 0.00000000e+00, 4.70991785e-04,\n",
              "       3.31121466e-04, 5.30312033e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.82512214e-04, 2.56407159e-04, 0.00000000e+00,\n",
              "       1.66158116e-03, 0.00000000e+00, 0.00000000e+00, 8.75900598e-05,\n",
              "       0.00000000e+00, 1.04350880e-03, 3.46461518e-03, 0.00000000e+00,\n",
              "       1.23680738e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.52208297e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.29233938e-05, 0.00000000e+00,\n",
              "       4.73809136e-04, 1.00676479e-03, 4.45250094e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.01465554e-04, 0.00000000e+00,\n",
              "       6.72431676e-04, 1.39112783e-03, 4.54130380e-03, 0.00000000e+00,\n",
              "       1.38544321e-04, 2.53340940e-02, 5.30009984e-04, 0.00000000e+00,\n",
              "       1.62979757e-02, 1.67942511e-03, 1.07011120e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.21769253e-03, 1.58511764e-02,\n",
              "       8.66768304e-04, 2.43097522e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.96533273e-03, 0.00000000e+00, 0.00000000e+00, 7.75587212e-03,\n",
              "       6.79807493e-05, 5.82736422e-04, 4.57755805e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.27706961e-03, 8.02743879e-04,\n",
              "       4.10338201e-03, 4.30072549e-04, 0.00000000e+00, 5.60652002e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.57888405e-03, 0.00000000e+00, 5.55899340e-04, 0.00000000e+00,\n",
              "       9.10796852e-05, 0.00000000e+00, 0.00000000e+00, 1.78571282e-03,\n",
              "       8.40857373e-04, 1.22461153e-03, 2.91830237e-04, 1.48518341e-03,\n",
              "       0.00000000e+00, 8.25483137e-04, 0.00000000e+00, 1.24849311e-02,\n",
              "       1.49493121e-03, 1.62677476e-03, 3.65327181e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.44411753e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.32344216e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.69460065e-04, 8.91710313e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.52837364e-04, 0.00000000e+00,\n",
              "       3.92769969e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.79623948e-03, 0.00000000e+00, 0.00000000e+00, 2.74789924e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.05433963e-03, 5.66462105e-03,\n",
              "       1.06260136e-03, 5.61808485e-04, 2.59521667e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.21756494e-04, 4.40133310e-04,\n",
              "       0.00000000e+00, 7.54358634e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.18001823e-05, 5.19740408e-04, 9.26505721e-05, 0.00000000e+00,\n",
              "       1.87315426e-03, 0.00000000e+00, 3.55653978e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.66898088e-02, 1.02104852e-02,\n",
              "       4.86586892e-04, 2.05155910e-03, 1.71279859e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.49787851e-03, 1.01919075e-02, 4.29244604e-03,\n",
              "       2.28882338e-03, 0.00000000e+00, 1.05361709e-02, 0.00000000e+00,\n",
              "       1.87355505e-02, 0.00000000e+00, 2.97092740e-03, 8.11481801e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.76882835e-04, 4.91454346e-03,\n",
              "       1.25870471e-03, 4.41300816e-03, 0.00000000e+00, 5.54293215e-03,\n",
              "       5.72924691e-03, 7.18894040e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 8.54314221e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.73823625e-04, 0.00000000e+00, 0.00000000e+00, 6.19812430e-03,\n",
              "       0.00000000e+00, 1.07825347e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.75785430e-04, 8.91111258e-04, 8.21642907e-04, 4.15047253e-03,\n",
              "       0.00000000e+00, 1.62185687e-03, 0.00000000e+00, 1.10392072e-03,\n",
              "       0.00000000e+00, 2.08837807e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.57180939e-04, 4.65040031e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.14883529e-03, 0.00000000e+00, 8.69482597e-05,\n",
              "       4.83544540e-04, 4.90843024e-04, 5.96931747e-04, 8.91460744e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.37826303e-04, 0.00000000e+00, 8.45961846e-05, 0.00000000e+00,\n",
              "       4.66902523e-04, 6.82407959e-04, 3.82249595e-03, 1.71255804e-03,\n",
              "       9.09433087e-04, 4.75375890e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.31157980e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.75873355e-03, 0.00000000e+00, 1.23420371e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.37854185e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.77428738e-03, 1.19630667e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.91717458e-04, 8.33406036e-04, 0.00000000e+00, 8.10052812e-04,\n",
              "       0.00000000e+00, 2.70297386e-03, 0.00000000e+00, 1.12457186e-03,\n",
              "       2.64507048e-03, 0.00000000e+00, 0.00000000e+00, 4.12488435e-04,\n",
              "       0.00000000e+00, 6.79710498e-04, 0.00000000e+00, 1.75005654e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.76452936e-04, 3.57317733e-04,\n",
              "       0.00000000e+00, 1.12317827e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.30254425e-03, 1.17235074e-03, 0.00000000e+00, 1.52521567e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.61023499e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.93284870e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.72615974e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.95361879e-04, 5.35229716e-03,\n",
              "       1.03615889e-02, 1.55133943e-02, 2.51286876e-02, 4.09909133e-03,\n",
              "       4.98432848e-03, 0.00000000e+00, 0.00000000e+00, 9.25039925e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.53384077e-03, 1.09728800e-02, 9.45433461e-03,\n",
              "       7.24628960e-05, 0.00000000e+00, 1.09204189e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.15912176e-03, 6.05798109e-04, 9.77975659e-04,\n",
              "       5.20385020e-03, 0.00000000e+00, 4.74830308e-03, 0.00000000e+00,\n",
              "       1.88444831e-02, 0.00000000e+00, 1.42329794e-03, 1.74638059e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.12488315e-04, 4.45419860e-04,\n",
              "       3.63060905e-03, 0.00000000e+00, 5.74913618e-04, 9.86386076e-03,\n",
              "       5.61985961e-04, 2.34536173e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.38699033e-04, 0.00000000e+00, 0.00000000e+00, 1.77437852e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.90777413e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.85621991e-04, 0.00000000e+00, 5.40855356e-04, 1.35043481e-03,\n",
              "       1.43131294e-03, 5.68728446e-04, 1.81096908e-03, 7.36915193e-04,\n",
              "       1.18306415e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.06367731e-03, 1.12226826e-03,\n",
              "       2.11471290e-04, 2.48705991e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.86926077e-03, 0.00000000e+00, 9.80239964e-04,\n",
              "       4.69335685e-04, 0.00000000e+00, 8.59979504e-05, 1.72942140e-03,\n",
              "       1.33133893e-03, 0.00000000e+00, 5.40834364e-04, 1.03971487e-03,\n",
              "       0.00000000e+00, 6.68479060e-04, 0.00000000e+00, 5.68741919e-04,\n",
              "       0.00000000e+00, 1.44405869e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.69110924e-03, 5.98268680e-03, 1.30418562e-03, 1.42421617e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.50262478e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 8.85388496e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.48415115e-05,\n",
              "       0.00000000e+00, 1.44455710e-03, 0.00000000e+00, 1.11169985e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.75511962e-03,\n",
              "       0.00000000e+00, 1.03241110e-03, 1.15259184e-03, 8.36928433e-05,\n",
              "       8.93665488e-05, 8.19296124e-04, 1.00559874e-03, 0.00000000e+00,\n",
              "       1.95347125e-03, 1.33638924e-03, 4.37852899e-04, 0.00000000e+00,\n",
              "       1.70729734e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.55351189e-04, 9.21724270e-04, 0.00000000e+00, 1.48384244e-03,\n",
              "       6.47999447e-04, 0.00000000e+00, 4.13183020e-02, 1.23496754e-03,\n",
              "       1.24663349e-02, 0.00000000e+00, 1.55591735e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.05613500e-02, 0.00000000e+00, 9.24980347e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.93956002e-03, 0.00000000e+00,\n",
              "       4.80992149e-03, 6.04115530e-03, 3.62760292e-03, 9.25010856e-03,\n",
              "       0.00000000e+00, 1.09865808e-02, 6.70639148e-04, 0.00000000e+00,\n",
              "       2.19526185e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.20938022e-03, 0.00000000e+00, 6.73951887e-04,\n",
              "       8.86445281e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.10208113e-03, 2.51092270e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.95311288e-03, 3.42808292e-03,\n",
              "       0.00000000e+00, 1.71957319e-04, 1.09740477e-03, 8.57604183e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.50189037e-03, 3.65606739e-04,\n",
              "       0.00000000e+00, 4.52716218e-03, 0.00000000e+00, 5.38691357e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.68369012e-03, 0.00000000e+00, 3.83613461e-05, 2.22060440e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6aqtSxMvhKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "fdfc1446-b921-458d-bd1b-b522fbbca9cf"
      },
      "source": [
        " sorted(zip(rank_features, data.columns), reverse=True)[:10]\n",
        " #ATTENZIONE HA SENSO SOLO SE NON SI FA PCA"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.041318302018261664, 'TEXTURE_NGTDM_ET_T1Gd_Coarseness'),\n",
              " (0.03400465904874065, 'VOLUME_ET_OVER_WT'),\n",
              " (0.025334093972020345, 'TEXTURE_GLCM_ET_T2_SumAverage'),\n",
              " (0.02512868756014921, 'TEXTURE_GLSZM_ET_T1Gd_ZSV'),\n",
              " (0.023453617320808272, 'TEXTURE_GLSZM_ET_FLAIR_ZSV'),\n",
              " (0.018844483106024136, 'TEXTURE_GLSZM_ET_T2_ZSV'),\n",
              " (0.018735550548136387, 'TEXTURE_GLRLM_ET_T2_RLV'),\n",
              " (0.01712798594740268, 'TEXTURE_GLRLM_ET_T2_GLN'),\n",
              " (0.016689808795072394, 'TEXTURE_GLRLM_ET_T1_GLV'),\n",
              " (0.016297975692483625, 'TEXTURE_GLCM_ET_T2_AutoCorrelation')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KBcqHaxUD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "a8d24785-7327-4528-9694-327428f31480"
      },
      "source": [
        ""
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('red_dim',\n",
              "                 PCA(copy=True, iterated_power='auto', n_components=0.9,\n",
              "                     random_state=42, svd_solver='auto', tol=0.0,\n",
              "                     whiten=False)),\n",
              "                ('clf',\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight='balanced',\n",
              "                                        criterion='gini', max_depth=10,\n",
              "                                        max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=2, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=150, n_jobs=None,\n",
              "                                        oob_score=False, random_state=503,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6J3anCRcVlg",
        "colab_type": "code",
        "outputId": "7ca2534f-b77a-4749-8822-7000d241efbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "for i in range(1, 6):\n",
        "\n",
        "    #Train test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(public_data, public_labels, test_size=0.3, \n",
        "    stratify=public_labels, random_state=i*500)\n",
        "\n",
        "    #Vettorizzare i label\n",
        "    train_labels_encoded = encoder.fit_transform(y_train)\n",
        "    test_labels_encoded = encoder.transform(y_test)\n",
        "\n",
        "    #RandomForestClassifier\n",
        "    steps = [('scaler', StandardScaler()), ('red_dim', PCA()), ('clf', RandomForestClassifier(random_state=i*503))]\n",
        "\n",
        "    pipeline = Pipeline(steps)\n",
        "\n",
        "    parameteres = [{'scaler':scalers_to_test, 'red_dim':[PCA(random_state=42)], 'red_dim__n_components':list(n_features_to_test),\n",
        "                    'red_dim__whiten':[False, True], \n",
        "                    'clf__n_estimators':list(n_tree), 'clf__criterion':['gini', 'entropy'], \n",
        "                    'clf__max_depth':depth, 'clf__min_samples_split':[2, 5, 10], \n",
        "                    'clf__min_samples_leaf':[1, 2, 4], 'clf__class_weight':[None, 'balanced']}]\n",
        "\n",
        "    grid = GridSearchCV(pipeline, param_grid=parameteres, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "     grid.fit(X_train, y_train)\n",
        "\n",
        "    score_train = grid.score(X_train, y_train)\n",
        "    score_test = grid.score(X_test, y_test)\n",
        "    best_p = grid.best_params_\n",
        "\n",
        "    bp = pd.DataFrame(best_p, index=[i])\n",
        "    bp['accuracy_train'] = score_train\n",
        "    bp['accuracy_test'] = score_test\n",
        "    bp['random_state'] = i*500\n",
        "    bp['random_state_pca'] = i*42\n",
        "    bp['random_state_clf'] = i*503\n",
        "\n",
        "    df = df.append(bp, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-936043f88c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     X_train, X_test, y_train, y_test = train_test_split(public_data, public_labels, test_size=0.3, \n\u001b[0m\u001b[1;32m     11\u001b[0m     stratify=public_labels, random_state=i*500)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'public_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYtNggBRaf2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ROe5ga1fue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D={i:0}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dDNMU1z1jJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9493a8-4eb9-440f-974c-641e89a9c1ad"
      },
      "source": [
        "D"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvrS2Iqw1j__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}