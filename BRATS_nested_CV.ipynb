{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BRATS_nested_CV.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYGH00zeT2wevtkxDVKCq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardoub/cmepda/blob/master/BRATS_nested_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BthL8ZcBZ44G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0sTf8q1IrI",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyyNl4gxhEwD",
        "colab_type": "code",
        "outputId": "2e635112-f293-41a0-8a6c-7fee244499db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#load data from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCkUXesZhMzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/gdrive/My Drive/BRATS/data_without_NAN_with_histologies.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TczPxOpEhTXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.read_csv(dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znKJzW7bsbx",
        "colab_type": "code",
        "outputId": "f943fb43-60e1-421c-98e4-f54a153b024c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>Date</th>\n",
              "      <th>VOLUME_ET</th>\n",
              "      <th>VOLUME_NET</th>\n",
              "      <th>VOLUME_ED</th>\n",
              "      <th>VOLUME_TC</th>\n",
              "      <th>VOLUME_WT</th>\n",
              "      <th>VOLUME_BRAIN</th>\n",
              "      <th>VOLUME_ET_OVER_NET</th>\n",
              "      <th>VOLUME_ET_OVER_ED</th>\n",
              "      <th>VOLUME_NET_OVER_ED</th>\n",
              "      <th>VOLUME_ET_over_TC</th>\n",
              "      <th>VOLUME_NET_over_TC</th>\n",
              "      <th>VOLUME_ED_over_TC</th>\n",
              "      <th>VOLUME_ET_OVER_WT</th>\n",
              "      <th>VOLUME_NET_OVER_WT</th>\n",
              "      <th>VOLUME_ED_OVER_WT</th>\n",
              "      <th>VOLUME_TC_OVER_WT</th>\n",
              "      <th>VOLUME_ET_OVER_BRAIN</th>\n",
              "      <th>VOLUME_NET_OVER_BRAIN</th>\n",
              "      <th>VOLUME_ED_over_BRAIN</th>\n",
              "      <th>VOLUME_TC_over_BRAIN</th>\n",
              "      <th>VOLUME_WT_OVER_BRAIN</th>\n",
              "      <th>DIST_Vent_TC</th>\n",
              "      <th>DIST_Vent_ED</th>\n",
              "      <th>INTENSITY_Mean_ET_T1Gd</th>\n",
              "      <th>INTENSITY_STD_ET_T1Gd</th>\n",
              "      <th>INTENSITY_Mean_ET_T1</th>\n",
              "      <th>INTENSITY_STD_ET_T1</th>\n",
              "      <th>INTENSITY_Mean_ET_T2</th>\n",
              "      <th>INTENSITY_STD_ET_T2</th>\n",
              "      <th>INTENSITY_Mean_ET_FLAIR</th>\n",
              "      <th>INTENSITY_STD_ET_FLAIR</th>\n",
              "      <th>INTENSITY_Mean_NET_T1Gd</th>\n",
              "      <th>INTENSITY_STD_NET_T1Gd</th>\n",
              "      <th>INTENSITY_Mean_NET_T1</th>\n",
              "      <th>INTENSITY_STD_NET_T1</th>\n",
              "      <th>INTENSITY_Mean_NET_T2</th>\n",
              "      <th>INTENSITY_STD_NET_T2</th>\n",
              "      <th>...</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T1_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_T2_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_ED_FLAIR_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1Gd_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T1_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_T2_Strength</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Coarseness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Contrast</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Busyness</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Complexity</th>\n",
              "      <th>TEXTURE_NGTDM_NET_FLAIR_Strength</th>\n",
              "      <th>TGM_p1</th>\n",
              "      <th>TGM_dw</th>\n",
              "      <th>TGM_Cog_X_1</th>\n",
              "      <th>TGM_Cog_Y_1</th>\n",
              "      <th>TGM_Cog_Z_1</th>\n",
              "      <th>TGM_T_1</th>\n",
              "      <th>Histology</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TCGA-02-0006</td>\n",
              "      <td>1996.08.23</td>\n",
              "      <td>1662</td>\n",
              "      <td>384</td>\n",
              "      <td>36268</td>\n",
              "      <td>2046</td>\n",
              "      <td>38314</td>\n",
              "      <td>1469432</td>\n",
              "      <td>4.328125</td>\n",
              "      <td>0.045826</td>\n",
              "      <td>0.010588</td>\n",
              "      <td>0.812320</td>\n",
              "      <td>0.187680</td>\n",
              "      <td>17.726300</td>\n",
              "      <td>0.043378</td>\n",
              "      <td>0.010022</td>\n",
              "      <td>0.946599</td>\n",
              "      <td>0.053401</td>\n",
              "      <td>0.001131</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.024682</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.026074</td>\n",
              "      <td>31.5903</td>\n",
              "      <td>2.7735</td>\n",
              "      <td>149.7977</td>\n",
              "      <td>10.4671</td>\n",
              "      <td>194.1422</td>\n",
              "      <td>15.1037</td>\n",
              "      <td>154.9225</td>\n",
              "      <td>43.4709</td>\n",
              "      <td>220.5894</td>\n",
              "      <td>30.2917</td>\n",
              "      <td>137.8881</td>\n",
              "      <td>6.3820</td>\n",
              "      <td>183.6933</td>\n",
              "      <td>14.8846</td>\n",
              "      <td>161.1005</td>\n",
              "      <td>35.8591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.86315</td>\n",
              "      <td>1479.9762</td>\n",
              "      <td>1.10870</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>0.40937</td>\n",
              "      <td>1.47070</td>\n",
              "      <td>2992.2698</td>\n",
              "      <td>0.71642</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.28977</td>\n",
              "      <td>1.8815</td>\n",
              "      <td>1872.0528</td>\n",
              "      <td>0.75986</td>\n",
              "      <td>0.026040</td>\n",
              "      <td>0.37869</td>\n",
              "      <td>0.060929</td>\n",
              "      <td>1675.0041</td>\n",
              "      <td>14.11380</td>\n",
              "      <td>0.044156</td>\n",
              "      <td>0.41942</td>\n",
              "      <td>0.026740</td>\n",
              "      <td>2536.7559</td>\n",
              "      <td>43.31290</td>\n",
              "      <td>0.036634</td>\n",
              "      <td>0.50304</td>\n",
              "      <td>0.024264</td>\n",
              "      <td>3593.3279</td>\n",
              "      <td>43.67590</td>\n",
              "      <td>0.057204</td>\n",
              "      <td>0.33980</td>\n",
              "      <td>0.021897</td>\n",
              "      <td>2203.2034</td>\n",
              "      <td>61.32930</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.178609</td>\n",
              "      <td>0.096256</td>\n",
              "      <td>0.052741</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TCGA-02-0009</td>\n",
              "      <td>1997.06.14</td>\n",
              "      <td>4362</td>\n",
              "      <td>4349</td>\n",
              "      <td>15723</td>\n",
              "      <td>8711</td>\n",
              "      <td>24434</td>\n",
              "      <td>1295721</td>\n",
              "      <td>1.002989</td>\n",
              "      <td>0.277428</td>\n",
              "      <td>0.276601</td>\n",
              "      <td>0.500750</td>\n",
              "      <td>0.499250</td>\n",
              "      <td>1.805000</td>\n",
              "      <td>0.178522</td>\n",
              "      <td>0.177990</td>\n",
              "      <td>0.643489</td>\n",
              "      <td>0.356511</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.003356</td>\n",
              "      <td>0.012135</td>\n",
              "      <td>0.006723</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>9.2443</td>\n",
              "      <td>3.0207</td>\n",
              "      <td>165.4345</td>\n",
              "      <td>6.4047</td>\n",
              "      <td>201.2400</td>\n",
              "      <td>13.4733</td>\n",
              "      <td>113.1601</td>\n",
              "      <td>10.1373</td>\n",
              "      <td>210.1810</td>\n",
              "      <td>15.9543</td>\n",
              "      <td>152.6013</td>\n",
              "      <td>4.2360</td>\n",
              "      <td>188.0607</td>\n",
              "      <td>11.1316</td>\n",
              "      <td>116.8538</td>\n",
              "      <td>10.0992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.40004</td>\n",
              "      <td>2378.9184</td>\n",
              "      <td>2.54730</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.70926</td>\n",
              "      <td>0.78063</td>\n",
              "      <td>5719.2847</td>\n",
              "      <td>1.29980</td>\n",
              "      <td>0.000882</td>\n",
              "      <td>0.48919</td>\n",
              "      <td>1.8243</td>\n",
              "      <td>2954.8148</td>\n",
              "      <td>0.77199</td>\n",
              "      <td>0.002254</td>\n",
              "      <td>0.29324</td>\n",
              "      <td>1.223600</td>\n",
              "      <td>539.3057</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.005712</td>\n",
              "      <td>0.20995</td>\n",
              "      <td>0.315580</td>\n",
              "      <td>967.7845</td>\n",
              "      <td>3.74440</td>\n",
              "      <td>0.003790</td>\n",
              "      <td>0.36163</td>\n",
              "      <td>0.271420</td>\n",
              "      <td>1996.1440</td>\n",
              "      <td>2.77050</td>\n",
              "      <td>0.004966</td>\n",
              "      <td>0.28715</td>\n",
              "      <td>0.189980</td>\n",
              "      <td>1440.4285</td>\n",
              "      <td>3.59990</td>\n",
              "      <td>3.31250</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.077618</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.094336</td>\n",
              "      <td>91.47360</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TCGA-02-0011</td>\n",
              "      <td>1998.02.01</td>\n",
              "      <td>33404</td>\n",
              "      <td>48612</td>\n",
              "      <td>45798</td>\n",
              "      <td>82016</td>\n",
              "      <td>127814</td>\n",
              "      <td>1425843</td>\n",
              "      <td>0.687155</td>\n",
              "      <td>0.729377</td>\n",
              "      <td>1.061444</td>\n",
              "      <td>0.407290</td>\n",
              "      <td>0.592710</td>\n",
              "      <td>0.558400</td>\n",
              "      <td>0.261349</td>\n",
              "      <td>0.380334</td>\n",
              "      <td>0.358318</td>\n",
              "      <td>0.641682</td>\n",
              "      <td>0.023428</td>\n",
              "      <td>0.034094</td>\n",
              "      <td>0.032120</td>\n",
              "      <td>0.057521</td>\n",
              "      <td>0.089641</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>186.3385</td>\n",
              "      <td>17.6126</td>\n",
              "      <td>188.2019</td>\n",
              "      <td>23.5195</td>\n",
              "      <td>172.8969</td>\n",
              "      <td>32.7401</td>\n",
              "      <td>167.1395</td>\n",
              "      <td>34.1684</td>\n",
              "      <td>149.0643</td>\n",
              "      <td>12.9090</td>\n",
              "      <td>158.4197</td>\n",
              "      <td>15.2632</td>\n",
              "      <td>197.4966</td>\n",
              "      <td>27.1781</td>\n",
              "      <td>...</td>\n",
              "      <td>1.51780</td>\n",
              "      <td>1750.3404</td>\n",
              "      <td>0.56482</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.59301</td>\n",
              "      <td>1.81810</td>\n",
              "      <td>4990.3388</td>\n",
              "      <td>0.54747</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.59184</td>\n",
              "      <td>2.4243</td>\n",
              "      <td>4703.9458</td>\n",
              "      <td>0.41937</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>0.37863</td>\n",
              "      <td>1.957500</td>\n",
              "      <td>2509.3979</td>\n",
              "      <td>0.42842</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>0.19849</td>\n",
              "      <td>1.395800</td>\n",
              "      <td>1322.6082</td>\n",
              "      <td>0.74730</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>0.31856</td>\n",
              "      <td>1.144300</td>\n",
              "      <td>2517.8629</td>\n",
              "      <td>0.84294</td>\n",
              "      <td>0.000794</td>\n",
              "      <td>0.17961</td>\n",
              "      <td>1.068800</td>\n",
              "      <td>1147.5177</td>\n",
              "      <td>0.80480</td>\n",
              "      <td>5.78125</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.132283</td>\n",
              "      <td>0.116006</td>\n",
              "      <td>0.096035</td>\n",
              "      <td>272.42900</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TCGA-02-0027</td>\n",
              "      <td>1999.03.28</td>\n",
              "      <td>12114</td>\n",
              "      <td>7587</td>\n",
              "      <td>34086</td>\n",
              "      <td>19701</td>\n",
              "      <td>53787</td>\n",
              "      <td>1403429</td>\n",
              "      <td>1.596679</td>\n",
              "      <td>0.355395</td>\n",
              "      <td>0.222584</td>\n",
              "      <td>0.614890</td>\n",
              "      <td>0.385110</td>\n",
              "      <td>1.730200</td>\n",
              "      <td>0.225222</td>\n",
              "      <td>0.141056</td>\n",
              "      <td>0.633722</td>\n",
              "      <td>0.366278</td>\n",
              "      <td>0.008632</td>\n",
              "      <td>0.005406</td>\n",
              "      <td>0.024288</td>\n",
              "      <td>0.014038</td>\n",
              "      <td>0.038325</td>\n",
              "      <td>1.0331</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>178.6925</td>\n",
              "      <td>23.1751</td>\n",
              "      <td>199.7626</td>\n",
              "      <td>27.0047</td>\n",
              "      <td>157.0192</td>\n",
              "      <td>25.6793</td>\n",
              "      <td>173.6525</td>\n",
              "      <td>26.3596</td>\n",
              "      <td>120.3726</td>\n",
              "      <td>17.5926</td>\n",
              "      <td>199.5765</td>\n",
              "      <td>25.3652</td>\n",
              "      <td>194.2708</td>\n",
              "      <td>24.5411</td>\n",
              "      <td>...</td>\n",
              "      <td>0.78104</td>\n",
              "      <td>1870.7630</td>\n",
              "      <td>1.37070</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.65247</td>\n",
              "      <td>1.46450</td>\n",
              "      <td>5625.0240</td>\n",
              "      <td>0.66930</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.66446</td>\n",
              "      <td>1.5863</td>\n",
              "      <td>5585.3565</td>\n",
              "      <td>0.60995</td>\n",
              "      <td>0.001456</td>\n",
              "      <td>0.89121</td>\n",
              "      <td>0.485160</td>\n",
              "      <td>7372.7070</td>\n",
              "      <td>2.03510</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.23036</td>\n",
              "      <td>0.143560</td>\n",
              "      <td>1722.6804</td>\n",
              "      <td>6.94490</td>\n",
              "      <td>0.002126</td>\n",
              "      <td>0.54383</td>\n",
              "      <td>0.379490</td>\n",
              "      <td>3698.6228</td>\n",
              "      <td>2.31820</td>\n",
              "      <td>0.003284</td>\n",
              "      <td>0.41179</td>\n",
              "      <td>0.206600</td>\n",
              "      <td>3320.1690</td>\n",
              "      <td>4.73360</td>\n",
              "      <td>3.87500</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.100415</td>\n",
              "      <td>0.088249</td>\n",
              "      <td>0.096470</td>\n",
              "      <td>128.46800</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TCGA-02-0033</td>\n",
              "      <td>1997.05.26</td>\n",
              "      <td>34538</td>\n",
              "      <td>7137</td>\n",
              "      <td>65653</td>\n",
              "      <td>41675</td>\n",
              "      <td>107328</td>\n",
              "      <td>1365237</td>\n",
              "      <td>4.839288</td>\n",
              "      <td>0.526069</td>\n",
              "      <td>0.108708</td>\n",
              "      <td>0.828750</td>\n",
              "      <td>0.171250</td>\n",
              "      <td>1.575400</td>\n",
              "      <td>0.321799</td>\n",
              "      <td>0.066497</td>\n",
              "      <td>0.611704</td>\n",
              "      <td>0.388296</td>\n",
              "      <td>0.025298</td>\n",
              "      <td>0.005228</td>\n",
              "      <td>0.048089</td>\n",
              "      <td>0.030526</td>\n",
              "      <td>0.078615</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>172.4109</td>\n",
              "      <td>27.5731</td>\n",
              "      <td>121.4969</td>\n",
              "      <td>10.3061</td>\n",
              "      <td>148.9331</td>\n",
              "      <td>27.8493</td>\n",
              "      <td>159.0135</td>\n",
              "      <td>23.9666</td>\n",
              "      <td>116.9944</td>\n",
              "      <td>8.2358</td>\n",
              "      <td>117.7009</td>\n",
              "      <td>9.9957</td>\n",
              "      <td>139.4320</td>\n",
              "      <td>34.3293</td>\n",
              "      <td>...</td>\n",
              "      <td>1.80660</td>\n",
              "      <td>1959.4667</td>\n",
              "      <td>0.56070</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>0.48428</td>\n",
              "      <td>2.18490</td>\n",
              "      <td>4083.7014</td>\n",
              "      <td>0.46492</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.40305</td>\n",
              "      <td>1.8266</td>\n",
              "      <td>3592.2992</td>\n",
              "      <td>0.56135</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>0.42666</td>\n",
              "      <td>0.950220</td>\n",
              "      <td>2072.5900</td>\n",
              "      <td>1.17490</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.14562</td>\n",
              "      <td>0.713820</td>\n",
              "      <td>538.8446</td>\n",
              "      <td>1.14360</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>0.47817</td>\n",
              "      <td>0.555670</td>\n",
              "      <td>3020.3680</td>\n",
              "      <td>1.90570</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.31043</td>\n",
              "      <td>0.413750</td>\n",
              "      <td>1834.1052</td>\n",
              "      <td>2.45320</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>5.725000e-08</td>\n",
              "      <td>0.106184</td>\n",
              "      <td>0.131952</td>\n",
              "      <td>0.096894</td>\n",
              "      <td>240.77800</td>\n",
              "      <td>GBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>TCGA-HT-7694</td>\n",
              "      <td>1995.04.04</td>\n",
              "      <td>1036</td>\n",
              "      <td>189152</td>\n",
              "      <td>171595</td>\n",
              "      <td>190188</td>\n",
              "      <td>361783</td>\n",
              "      <td>1611350</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.006037</td>\n",
              "      <td>1.102317</td>\n",
              "      <td>0.005447</td>\n",
              "      <td>0.994550</td>\n",
              "      <td>0.902240</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>0.522833</td>\n",
              "      <td>0.474304</td>\n",
              "      <td>0.525696</td>\n",
              "      <td>0.000643</td>\n",
              "      <td>0.117387</td>\n",
              "      <td>0.106490</td>\n",
              "      <td>0.118030</td>\n",
              "      <td>0.224522</td>\n",
              "      <td>1.5561</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>130.5401</td>\n",
              "      <td>10.8604</td>\n",
              "      <td>158.2426</td>\n",
              "      <td>5.1363</td>\n",
              "      <td>160.5840</td>\n",
              "      <td>13.3742</td>\n",
              "      <td>196.0449</td>\n",
              "      <td>12.1558</td>\n",
              "      <td>85.7372</td>\n",
              "      <td>14.1637</td>\n",
              "      <td>135.7749</td>\n",
              "      <td>12.9578</td>\n",
              "      <td>172.2660</td>\n",
              "      <td>25.9874</td>\n",
              "      <td>...</td>\n",
              "      <td>3.89200</td>\n",
              "      <td>1050.8760</td>\n",
              "      <td>0.26584</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.28803</td>\n",
              "      <td>3.76680</td>\n",
              "      <td>2246.2262</td>\n",
              "      <td>0.26343</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.32326</td>\n",
              "      <td>3.7144</td>\n",
              "      <td>2862.7663</td>\n",
              "      <td>0.26864</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.39033</td>\n",
              "      <td>4.843700</td>\n",
              "      <td>3149.1624</td>\n",
              "      <td>0.20185</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.17338</td>\n",
              "      <td>4.129200</td>\n",
              "      <td>1181.3019</td>\n",
              "      <td>0.23864</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.33542</td>\n",
              "      <td>4.444300</td>\n",
              "      <td>2706.6360</td>\n",
              "      <td>0.22259</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.25558</td>\n",
              "      <td>3.698700</td>\n",
              "      <td>2033.8540</td>\n",
              "      <td>0.26785</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000e-09</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.070503</td>\n",
              "      <td>0.090456</td>\n",
              "      <td>719.23800</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>142</td>\n",
              "      <td>TCGA-HT-8018</td>\n",
              "      <td>1997.04.11</td>\n",
              "      <td>2093</td>\n",
              "      <td>8685</td>\n",
              "      <td>39142</td>\n",
              "      <td>10778</td>\n",
              "      <td>49920</td>\n",
              "      <td>1493262</td>\n",
              "      <td>0.240990</td>\n",
              "      <td>0.053472</td>\n",
              "      <td>0.221884</td>\n",
              "      <td>0.194190</td>\n",
              "      <td>0.805810</td>\n",
              "      <td>3.631700</td>\n",
              "      <td>0.041927</td>\n",
              "      <td>0.173978</td>\n",
              "      <td>0.784095</td>\n",
              "      <td>0.215905</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.005816</td>\n",
              "      <td>0.026212</td>\n",
              "      <td>0.007218</td>\n",
              "      <td>0.033430</td>\n",
              "      <td>7.8703</td>\n",
              "      <td>1.2296</td>\n",
              "      <td>122.5820</td>\n",
              "      <td>24.4042</td>\n",
              "      <td>90.7803</td>\n",
              "      <td>9.1876</td>\n",
              "      <td>189.3704</td>\n",
              "      <td>11.4401</td>\n",
              "      <td>176.2758</td>\n",
              "      <td>14.7584</td>\n",
              "      <td>81.0780</td>\n",
              "      <td>10.4078</td>\n",
              "      <td>88.8951</td>\n",
              "      <td>9.1065</td>\n",
              "      <td>189.3633</td>\n",
              "      <td>14.4565</td>\n",
              "      <td>...</td>\n",
              "      <td>0.56593</td>\n",
              "      <td>1255.6524</td>\n",
              "      <td>1.74930</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.48939</td>\n",
              "      <td>1.56420</td>\n",
              "      <td>3817.4564</td>\n",
              "      <td>0.62083</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.38268</td>\n",
              "      <td>1.2343</td>\n",
              "      <td>3032.0641</td>\n",
              "      <td>0.77990</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.37981</td>\n",
              "      <td>0.402750</td>\n",
              "      <td>2605.8492</td>\n",
              "      <td>2.57200</td>\n",
              "      <td>0.004937</td>\n",
              "      <td>0.14295</td>\n",
              "      <td>0.201910</td>\n",
              "      <td>882.1737</td>\n",
              "      <td>4.27000</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.37387</td>\n",
              "      <td>0.370130</td>\n",
              "      <td>2336.3329</td>\n",
              "      <td>2.22420</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>0.22536</td>\n",
              "      <td>0.200950</td>\n",
              "      <td>1446.4163</td>\n",
              "      <td>3.99730</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.168857</td>\n",
              "      <td>0.120586</td>\n",
              "      <td>0.054307</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>TCGA-HT-8111</td>\n",
              "      <td>1998.03.30</td>\n",
              "      <td>1929</td>\n",
              "      <td>437</td>\n",
              "      <td>54079</td>\n",
              "      <td>2366</td>\n",
              "      <td>56445</td>\n",
              "      <td>1821157</td>\n",
              "      <td>4.414188</td>\n",
              "      <td>0.035670</td>\n",
              "      <td>0.008081</td>\n",
              "      <td>0.815300</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>22.856700</td>\n",
              "      <td>0.034175</td>\n",
              "      <td>0.007742</td>\n",
              "      <td>0.958083</td>\n",
              "      <td>0.041917</td>\n",
              "      <td>0.001059</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.029695</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.030994</td>\n",
              "      <td>19.5113</td>\n",
              "      <td>2.7359</td>\n",
              "      <td>114.8266</td>\n",
              "      <td>16.4708</td>\n",
              "      <td>88.3256</td>\n",
              "      <td>5.7475</td>\n",
              "      <td>135.0452</td>\n",
              "      <td>10.8131</td>\n",
              "      <td>153.4996</td>\n",
              "      <td>7.2622</td>\n",
              "      <td>84.3018</td>\n",
              "      <td>8.0198</td>\n",
              "      <td>88.9795</td>\n",
              "      <td>5.3935</td>\n",
              "      <td>131.7430</td>\n",
              "      <td>11.2399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.80255</td>\n",
              "      <td>863.0606</td>\n",
              "      <td>1.39180</td>\n",
              "      <td>0.000547</td>\n",
              "      <td>0.34568</td>\n",
              "      <td>1.24340</td>\n",
              "      <td>2832.2946</td>\n",
              "      <td>0.78981</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.32099</td>\n",
              "      <td>1.6823</td>\n",
              "      <td>2470.0227</td>\n",
              "      <td>0.55317</td>\n",
              "      <td>0.017196</td>\n",
              "      <td>0.86464</td>\n",
              "      <td>0.061184</td>\n",
              "      <td>5330.9937</td>\n",
              "      <td>14.26100</td>\n",
              "      <td>0.053508</td>\n",
              "      <td>0.17277</td>\n",
              "      <td>0.029481</td>\n",
              "      <td>879.6829</td>\n",
              "      <td>34.79070</td>\n",
              "      <td>0.036952</td>\n",
              "      <td>0.26426</td>\n",
              "      <td>0.039567</td>\n",
              "      <td>1317.6443</td>\n",
              "      <td>22.83400</td>\n",
              "      <td>0.052586</td>\n",
              "      <td>0.20996</td>\n",
              "      <td>0.031829</td>\n",
              "      <td>803.8863</td>\n",
              "      <td>27.48750</td>\n",
              "      <td>1.96875</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.148932</td>\n",
              "      <td>0.073453</td>\n",
              "      <td>0.126712</td>\n",
              "      <td>7.06744</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>144</td>\n",
              "      <td>TCGA-HT-8114</td>\n",
              "      <td>1998.10.30</td>\n",
              "      <td>8755</td>\n",
              "      <td>168606</td>\n",
              "      <td>11325</td>\n",
              "      <td>177361</td>\n",
              "      <td>188686</td>\n",
              "      <td>1693971</td>\n",
              "      <td>0.051926</td>\n",
              "      <td>0.773068</td>\n",
              "      <td>14.887947</td>\n",
              "      <td>0.049363</td>\n",
              "      <td>0.950640</td>\n",
              "      <td>0.063853</td>\n",
              "      <td>0.046400</td>\n",
              "      <td>0.893580</td>\n",
              "      <td>0.060020</td>\n",
              "      <td>0.939980</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>0.099533</td>\n",
              "      <td>0.006686</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>0.111387</td>\n",
              "      <td>2.2261</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>92.3248</td>\n",
              "      <td>10.9722</td>\n",
              "      <td>96.4461</td>\n",
              "      <td>7.0449</td>\n",
              "      <td>120.4493</td>\n",
              "      <td>18.3507</td>\n",
              "      <td>168.2873</td>\n",
              "      <td>13.7084</td>\n",
              "      <td>76.0316</td>\n",
              "      <td>15.3670</td>\n",
              "      <td>98.1388</td>\n",
              "      <td>11.9586</td>\n",
              "      <td>127.2041</td>\n",
              "      <td>26.8906</td>\n",
              "      <td>...</td>\n",
              "      <td>0.31348</td>\n",
              "      <td>1119.2382</td>\n",
              "      <td>2.66250</td>\n",
              "      <td>0.001288</td>\n",
              "      <td>0.68191</td>\n",
              "      <td>0.60512</td>\n",
              "      <td>5246.9633</td>\n",
              "      <td>1.69490</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>1.15310</td>\n",
              "      <td>3.3277</td>\n",
              "      <td>6027.3574</td>\n",
              "      <td>0.55024</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.37937</td>\n",
              "      <td>4.644300</td>\n",
              "      <td>2996.8473</td>\n",
              "      <td>0.21714</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.15073</td>\n",
              "      <td>3.012000</td>\n",
              "      <td>1054.1171</td>\n",
              "      <td>0.36431</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.30578</td>\n",
              "      <td>3.346700</td>\n",
              "      <td>2515.2461</td>\n",
              "      <td>0.28794</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.25687</td>\n",
              "      <td>2.991600</td>\n",
              "      <td>2055.4227</td>\n",
              "      <td>0.30710</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>7.500000e-07</td>\n",
              "      <td>0.168182</td>\n",
              "      <td>0.167317</td>\n",
              "      <td>0.107433</td>\n",
              "      <td>15.52240</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145</td>\n",
              "      <td>TCGA-HT-8563</td>\n",
              "      <td>1998.12.09</td>\n",
              "      <td>11757</td>\n",
              "      <td>1012</td>\n",
              "      <td>138755</td>\n",
              "      <td>12769</td>\n",
              "      <td>151524</td>\n",
              "      <td>1605161</td>\n",
              "      <td>11.617589</td>\n",
              "      <td>0.084732</td>\n",
              "      <td>0.007293</td>\n",
              "      <td>0.920750</td>\n",
              "      <td>0.079254</td>\n",
              "      <td>10.866600</td>\n",
              "      <td>0.077592</td>\n",
              "      <td>0.006679</td>\n",
              "      <td>0.915730</td>\n",
              "      <td>0.084270</td>\n",
              "      <td>0.007324</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.086443</td>\n",
              "      <td>0.007955</td>\n",
              "      <td>0.094398</td>\n",
              "      <td>6.3847</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>154.6832</td>\n",
              "      <td>49.8662</td>\n",
              "      <td>103.6185</td>\n",
              "      <td>5.3827</td>\n",
              "      <td>108.7191</td>\n",
              "      <td>12.4944</td>\n",
              "      <td>168.1385</td>\n",
              "      <td>15.0086</td>\n",
              "      <td>87.1151</td>\n",
              "      <td>9.9561</td>\n",
              "      <td>98.4603</td>\n",
              "      <td>3.5746</td>\n",
              "      <td>112.2253</td>\n",
              "      <td>7.8119</td>\n",
              "      <td>...</td>\n",
              "      <td>3.98400</td>\n",
              "      <td>724.9046</td>\n",
              "      <td>0.26198</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.37976</td>\n",
              "      <td>3.41390</td>\n",
              "      <td>3293.8152</td>\n",
              "      <td>0.28105</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.29310</td>\n",
              "      <td>2.6220</td>\n",
              "      <td>2582.0410</td>\n",
              "      <td>0.36389</td>\n",
              "      <td>0.007180</td>\n",
              "      <td>1.27720</td>\n",
              "      <td>0.102260</td>\n",
              "      <td>10178.0572</td>\n",
              "      <td>9.39250</td>\n",
              "      <td>0.015050</td>\n",
              "      <td>0.23963</td>\n",
              "      <td>0.220530</td>\n",
              "      <td>731.4574</td>\n",
              "      <td>5.35820</td>\n",
              "      <td>0.015620</td>\n",
              "      <td>0.40833</td>\n",
              "      <td>0.076820</td>\n",
              "      <td>2324.7276</td>\n",
              "      <td>12.31230</td>\n",
              "      <td>0.028514</td>\n",
              "      <td>0.21704</td>\n",
              "      <td>0.065338</td>\n",
              "      <td>1056.9519</td>\n",
              "      <td>20.27440</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>3.213120e-07</td>\n",
              "      <td>0.072868</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.069101</td>\n",
              "      <td>7.62280</td>\n",
              "      <td>LGG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows × 708 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0            ID        Date  ...  TGM_Cog_Z_1    TGM_T_1  Histology\n",
              "0             0  TCGA-02-0006  1996.08.23  ...     0.052741    2.00000        GBM\n",
              "1             1  TCGA-02-0009  1997.06.14  ...     0.094336   91.47360        GBM\n",
              "2             2  TCGA-02-0011  1998.02.01  ...     0.096035  272.42900        GBM\n",
              "3             3  TCGA-02-0027  1999.03.28  ...     0.096470  128.46800        GBM\n",
              "4             4  TCGA-02-0033  1997.05.26  ...     0.096894  240.77800        GBM\n",
              "..          ...           ...         ...  ...          ...        ...        ...\n",
              "141         141  TCGA-HT-7694  1995.04.04  ...     0.090456  719.23800        LGG\n",
              "142         142  TCGA-HT-8018  1997.04.11  ...     0.054307    2.00000        LGG\n",
              "143         143  TCGA-HT-8111  1998.03.30  ...     0.126712    7.06744        LGG\n",
              "144         144  TCGA-HT-8114  1998.10.30  ...     0.107433   15.52240        LGG\n",
              "145         145  TCGA-HT-8563  1998.12.09  ...     0.069101    7.62280        LGG\n",
              "\n",
              "[146 rows x 708 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZviWnrbyAT",
        "colab_type": "code",
        "outputId": "18994018-1478-4f1c-dc98-87f2595ca0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "df_data.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ID', 'Date', 'VOLUME_ET', 'VOLUME_NET', 'VOLUME_ED',\n",
              "       'VOLUME_TC', 'VOLUME_WT', 'VOLUME_BRAIN', 'VOLUME_ET_OVER_NET',\n",
              "       ...\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Busyness',\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Complexity',\n",
              "       'TEXTURE_NGTDM_NET_FLAIR_Strength', 'TGM_p1', 'TGM_dw', 'TGM_Cog_X_1',\n",
              "       'TGM_Cog_Y_1', 'TGM_Cog_Z_1', 'TGM_T_1', 'Histology'],\n",
              "      dtype='object', length=708)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKKv4iKghWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df_data.drop(['Histology', 'Unnamed: 0', 'ID', 'Date'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu46pqnPhnCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df_data.Histology"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b_lnjdLcWEj",
        "colab_type": "text"
      },
      "source": [
        "#Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0hG99bXOxf7",
        "colab_type": "code",
        "outputId": "911d5ab5-30a7-47ee-bda9-89e31b4ffa3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV,KFold,cross_val_predict,cross_val_score,StratifiedKFold\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report,accuracy_score"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYvW7PB3Rqly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vettorizzare i label\n",
        "encoder = LabelEncoder()\n",
        "labels_encoded = encoder.fit_transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmG6Fx2eR-3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scalers\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "scalers_to_test = [StandardScaler(), RobustScaler(), MinMaxScaler(), None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcDzZhRSSCLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Designate distributions to sample hyperparameters from \n",
        "n_tree = [10, 50, 100, 150]\n",
        "n_features_to_test = [0.9]\n",
        "depth = [10, None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JigjLrG-Vp0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose cross-validation techniques for the inner and outer loops,\n",
        "# independently of the dataset.\n",
        "# E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wTioNOISOm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RandomForestClassifier\n",
        "steps = [('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state=503))]\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "parameteres = [{'scaler':[StandardScaler()], \n",
        "                'clf__n_estimators':list(n_tree), 'clf__criterion':['gini', 'entropy'], \n",
        "                'clf__max_depth':depth, 'clf__min_samples_split':[2, 5], \n",
        "                'clf__min_samples_leaf':[2, 4], 'clf__class_weight':[None, 'balanced']}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnj6__VFVbc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=inner_cv, n_jobs=-1, scoring='roc_auc', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOy1QLkWZNMv",
        "colab_type": "code",
        "outputId": "b5628418-eab0-43b6-9ef2-73ac03a55b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Nested CV with parameter optimization\n",
        "nested_score = cross_val_score(grid, X=data, y=labels_encoded, cv=outer_cv)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-e8e2f08bb3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKW1rFsNaR2n",
        "colab_type": "text"
      },
      "source": [
        "In questo modo non riesco a sapere quali sono i best HP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbZgiLfkaRe_",
        "colab_type": "code",
        "outputId": "735720fb-95e1-4289-fb72-e700f7a3f756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nested_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.81176471, 0.90784314, 0.88865546])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z5lfT0qXkIh",
        "colab_type": "text"
      },
      "source": [
        "questi dovrebbero essere i risultati del ciclo esterno di CV, ma con quali hp???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oT1Ld2cXZjv",
        "colab_type": "text"
      },
      "source": [
        "#ANOTHER WAY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3CYwBpIclrU",
        "colab_type": "code",
        "outputId": "701832a3-da66-4392-f3da-67a2d806fbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "train_index"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a3cd8a57426b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiZqSx_Yat3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMV4uK0Akehf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "014364a2-857d-4ddc-fbba-695a18d65188"
      },
      "source": [
        "dfObj.iloc[[2 ,0 ] , : ]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9f406580d3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dfObj' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSnfwj50liqq",
        "colab_type": "code",
        "outputId": "ec9ec81c-4452-4538-9508-ce910dda3373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "train_index"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a3cd8a57426b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F44Ru3-xlytR",
        "colab_type": "code",
        "outputId": "4bea8980-1916-4311-8a67-cd5eafc3a9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "labels_encoded[train_index]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-17e3bd7c074f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVfX7QlJXrtT",
        "colab_type": "code",
        "outputId": "3b3b0582-7cfc-4512-c4e9-64c66f1398de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "outer_loop_roc_auc_scores = []\n",
        "outer_loop_accuracy_scores = []\n",
        "inner_loop_won_params = []\n",
        "inner_loop_roc_auc_scores = []\n",
        "inner_loop_accuracy_scores = []\n",
        "best_est_dict = {}\n",
        "best_feat_dict = {}\n",
        "i = 0\n",
        "\n",
        "# Looping through the outer loop, feeding each training set into a GSCV as the inner loop\n",
        "for train_index, test_index in outer_cv.split(data, labels_encoded):\n",
        "    \n",
        "    i+=1\n",
        "\n",
        "    GSCV = GridSearchCV(pipeline, param_grid=parameteres, cv=inner_cv, n_jobs=-1, scoring=['roc_auc', 'accuracy'], refit='roc_auc', verbose=1)\n",
        "    \n",
        "    # GSCV is looping through the training data to find the best parameters. This is the inner loop\n",
        "    GSCV.fit(data.iloc[train_index, :], labels_encoded[train_index])\n",
        "    \n",
        "    # The best hyper parameters from GSCV is now being tested on the unseen outer loop test data.\n",
        "    pred = GSCV.predict(data.iloc[test_index, :])\n",
        "    \n",
        "\n",
        "    #per far uscire i best_estimators in qualche modo\n",
        "    best_est_dict.update({f'best_est_{i}' : GSCV.best_estimator_})\n",
        "\n",
        "    #The most important 10 features for the best estimator\n",
        "    #features_list =  sorted(zip(rank_features, data.columns), reverse=True)[:10]\n",
        "    #best_feat_dict.update({f'best_set_HP_{i}' : })\n",
        "\n",
        "\n",
        "    # Appending the \"winning\" hyper parameters and their associated accuracy score\n",
        "    inner_loop_won_params.append(GSCV.best_params_)\n",
        "    \n",
        "    outer_loop_roc_auc_scores.append(roc_auc_score(labels_encoded[test_index], pred))\n",
        "    outer_loop_accuracy_scores.append(accuracy_score(labels_encoded[test_index], pred))\n",
        "\n",
        "    inner_loop_roc_auc_scores.append(GSCV.best_score_)\n",
        "    #inner_loop_accuracy_scores.append(GSCV.best_score_)\n",
        "\n",
        "for i in zip(inner_loop_won_params, outer_loop_roc_auc_scores, inner_loop_roc_auc_scores):\n",
        "    print(i)\n",
        "\n",
        "#print('Mean of outer loop accuracy score:' np.mean(outer_loop_roc_auc_scores))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   28.6s\n",
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   55.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   53.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   11.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "({'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__n_estimators': 150, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.7852941176470588, 0.9476796955057823)\n",
            "({'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 150, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.9, 0.899026496852584)\n",
            "({'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 100, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, 0.8550420168067226, 0.9661396574440054)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   53.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2bFP40snboT",
        "colab_type": "code",
        "outputId": "14776f6b-351f-459b-b0a6-b1baab1c3f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inner_loop_roc_auc_scores"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9476796955057823, 0.899026496852584, 0.9661396574440054]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46GIyheq0VhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f195faa3-7a01-4711-a668-2372489e37cb"
      },
      "source": [
        "outer_loop_accuracy_scores"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8571428571428571, 0.9387755102040817, 0.8541666666666666]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCtgiIUpneJQ",
        "colab_type": "code",
        "outputId": "b163ffbf-a221-45d7-94f7-849e44986202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outer_loop_roc_auc_scores"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7852941176470588, 0.9, 0.8550420168067226]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYzH5o8atLSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank_features = GSCV.best_estimator_.named_steps[\"clf\"].feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPCzpd9Kx_SS",
        "colab_type": "code",
        "outputId": "12d0f522-8253-40c4-ed79-ad8deee235ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rank_features"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.18994501e-02, 0.00000000e+00, 0.00000000e+00, 1.40253842e-03,\n",
              "       0.00000000e+00, 1.00706678e-03, 8.79950020e-03, 1.34298453e-02,\n",
              "       0.00000000e+00, 1.01936147e-03, 5.50684222e-03, 0.00000000e+00,\n",
              "       3.40046590e-02, 4.59768202e-03, 1.85830321e-03, 1.98521201e-03,\n",
              "       1.09124774e-02, 3.40277778e-03, 0.00000000e+00, 1.66962165e-03,\n",
              "       5.63302809e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.41970641e-04, 0.00000000e+00, 5.39639614e-05,\n",
              "       3.10964476e-03, 8.69565217e-05, 0.00000000e+00, 6.88388284e-04,\n",
              "       9.41785018e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       7.12597700e-03, 8.85183902e-04, 0.00000000e+00, 9.44034812e-04,\n",
              "       4.65326605e-03, 9.34753194e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.45267017e-04, 0.00000000e+00, 9.26519962e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.00338666e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.15015208e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.02748777e-03, 0.00000000e+00, 1.25450785e-03,\n",
              "       0.00000000e+00, 1.95605196e-03, 7.23606363e-04, 1.78352005e-03,\n",
              "       0.00000000e+00, 2.41768370e-04, 6.71403409e-04, 0.00000000e+00,\n",
              "       1.04341994e-03, 8.41020163e-04, 9.58198413e-05, 7.95899747e-04,\n",
              "       1.18775366e-03, 1.04040634e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.33826202e-03, 9.75421671e-05, 8.73194812e-04,\n",
              "       0.00000000e+00, 1.00216415e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.48776964e-04, 0.00000000e+00, 1.88067342e-03, 8.52898734e-04,\n",
              "       1.03125130e-03, 1.71239771e-03, 4.60866352e-04, 0.00000000e+00,\n",
              "       1.03435860e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.36912774e-03, 0.00000000e+00, 1.59219738e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.58070145e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.40894097e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 8.93806032e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.06197410e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.93937612e-03,\n",
              "       0.00000000e+00, 6.14300871e-04, 0.00000000e+00, 2.07703859e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.46042999e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.70553629e-04, 2.30935604e-03, 4.58849082e-04,\n",
              "       6.29144049e-04, 0.00000000e+00, 4.76941993e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 8.88016458e-05, 4.60584482e-04, 4.25233470e-04,\n",
              "       0.00000000e+00, 3.46092859e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       6.90104254e-05, 9.50564569e-04, 1.01466289e-03, 1.06730195e-03,\n",
              "       8.62027684e-05, 9.07054123e-05, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.58440220e-03, 7.85245803e-05, 3.43554992e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.80335162e-04, 8.53843991e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.59746818e-03, 0.00000000e+00, 6.20860927e-05,\n",
              "       4.72689873e-04, 0.00000000e+00, 3.23027366e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 7.54988336e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.21773450e-04, 0.00000000e+00, 2.23493413e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.87581028e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.58188988e-03, 1.08023803e-03, 0.00000000e+00, 4.70991785e-04,\n",
              "       3.31121466e-04, 5.30312033e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.82512214e-04, 2.56407159e-04, 0.00000000e+00,\n",
              "       1.66158116e-03, 0.00000000e+00, 0.00000000e+00, 8.75900598e-05,\n",
              "       0.00000000e+00, 1.04350880e-03, 3.46461518e-03, 0.00000000e+00,\n",
              "       1.23680738e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.52208297e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.29233938e-05, 0.00000000e+00,\n",
              "       4.73809136e-04, 1.00676479e-03, 4.45250094e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.01465554e-04, 0.00000000e+00,\n",
              "       6.72431676e-04, 1.39112783e-03, 4.54130380e-03, 0.00000000e+00,\n",
              "       1.38544321e-04, 2.53340940e-02, 5.30009984e-04, 0.00000000e+00,\n",
              "       1.62979757e-02, 1.67942511e-03, 1.07011120e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.21769253e-03, 1.58511764e-02,\n",
              "       8.66768304e-04, 2.43097522e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.96533273e-03, 0.00000000e+00, 0.00000000e+00, 7.75587212e-03,\n",
              "       6.79807493e-05, 5.82736422e-04, 4.57755805e-04, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.27706961e-03, 8.02743879e-04,\n",
              "       4.10338201e-03, 4.30072549e-04, 0.00000000e+00, 5.60652002e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.57888405e-03, 0.00000000e+00, 5.55899340e-04, 0.00000000e+00,\n",
              "       9.10796852e-05, 0.00000000e+00, 0.00000000e+00, 1.78571282e-03,\n",
              "       8.40857373e-04, 1.22461153e-03, 2.91830237e-04, 1.48518341e-03,\n",
              "       0.00000000e+00, 8.25483137e-04, 0.00000000e+00, 1.24849311e-02,\n",
              "       1.49493121e-03, 1.62677476e-03, 3.65327181e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.44411753e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.32344216e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.69460065e-04, 8.91710313e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.52837364e-04, 0.00000000e+00,\n",
              "       3.92769969e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.79623948e-03, 0.00000000e+00, 0.00000000e+00, 2.74789924e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.05433963e-03, 5.66462105e-03,\n",
              "       1.06260136e-03, 5.61808485e-04, 2.59521667e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.21756494e-04, 4.40133310e-04,\n",
              "       0.00000000e+00, 7.54358634e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.18001823e-05, 5.19740408e-04, 9.26505721e-05, 0.00000000e+00,\n",
              "       1.87315426e-03, 0.00000000e+00, 3.55653978e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.66898088e-02, 1.02104852e-02,\n",
              "       4.86586892e-04, 2.05155910e-03, 1.71279859e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.49787851e-03, 1.01919075e-02, 4.29244604e-03,\n",
              "       2.28882338e-03, 0.00000000e+00, 1.05361709e-02, 0.00000000e+00,\n",
              "       1.87355505e-02, 0.00000000e+00, 2.97092740e-03, 8.11481801e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.76882835e-04, 4.91454346e-03,\n",
              "       1.25870471e-03, 4.41300816e-03, 0.00000000e+00, 5.54293215e-03,\n",
              "       5.72924691e-03, 7.18894040e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 8.54314221e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.73823625e-04, 0.00000000e+00, 0.00000000e+00, 6.19812430e-03,\n",
              "       0.00000000e+00, 1.07825347e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       4.75785430e-04, 8.91111258e-04, 8.21642907e-04, 4.15047253e-03,\n",
              "       0.00000000e+00, 1.62185687e-03, 0.00000000e+00, 1.10392072e-03,\n",
              "       0.00000000e+00, 2.08837807e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.57180939e-04, 4.65040031e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.14883529e-03, 0.00000000e+00, 8.69482597e-05,\n",
              "       4.83544540e-04, 4.90843024e-04, 5.96931747e-04, 8.91460744e-05,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.37826303e-04, 0.00000000e+00, 8.45961846e-05, 0.00000000e+00,\n",
              "       4.66902523e-04, 6.82407959e-04, 3.82249595e-03, 1.71255804e-03,\n",
              "       9.09433087e-04, 4.75375890e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.31157980e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.75873355e-03, 0.00000000e+00, 1.23420371e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.37854185e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.77428738e-03, 1.19630667e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.91717458e-04, 8.33406036e-04, 0.00000000e+00, 8.10052812e-04,\n",
              "       0.00000000e+00, 2.70297386e-03, 0.00000000e+00, 1.12457186e-03,\n",
              "       2.64507048e-03, 0.00000000e+00, 0.00000000e+00, 4.12488435e-04,\n",
              "       0.00000000e+00, 6.79710498e-04, 0.00000000e+00, 1.75005654e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.76452936e-04, 3.57317733e-04,\n",
              "       0.00000000e+00, 1.12317827e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.30254425e-03, 1.17235074e-03, 0.00000000e+00, 1.52521567e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.61023499e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.93284870e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.72615974e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.95361879e-04, 5.35229716e-03,\n",
              "       1.03615889e-02, 1.55133943e-02, 2.51286876e-02, 4.09909133e-03,\n",
              "       4.98432848e-03, 0.00000000e+00, 0.00000000e+00, 9.25039925e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.53384077e-03, 1.09728800e-02, 9.45433461e-03,\n",
              "       7.24628960e-05, 0.00000000e+00, 1.09204189e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 6.15912176e-03, 6.05798109e-04, 9.77975659e-04,\n",
              "       5.20385020e-03, 0.00000000e+00, 4.74830308e-03, 0.00000000e+00,\n",
              "       1.88444831e-02, 0.00000000e+00, 1.42329794e-03, 1.74638059e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 6.12488315e-04, 4.45419860e-04,\n",
              "       3.63060905e-03, 0.00000000e+00, 5.74913618e-04, 9.86386076e-03,\n",
              "       5.61985961e-04, 2.34536173e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.38699033e-04, 0.00000000e+00, 0.00000000e+00, 1.77437852e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 4.90777413e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "       5.85621991e-04, 0.00000000e+00, 5.40855356e-04, 1.35043481e-03,\n",
              "       1.43131294e-03, 5.68728446e-04, 1.81096908e-03, 7.36915193e-04,\n",
              "       1.18306415e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 1.06367731e-03, 1.12226826e-03,\n",
              "       2.11471290e-04, 2.48705991e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.86926077e-03, 0.00000000e+00, 9.80239964e-04,\n",
              "       4.69335685e-04, 0.00000000e+00, 8.59979504e-05, 1.72942140e-03,\n",
              "       1.33133893e-03, 0.00000000e+00, 5.40834364e-04, 1.03971487e-03,\n",
              "       0.00000000e+00, 6.68479060e-04, 0.00000000e+00, 5.68741919e-04,\n",
              "       0.00000000e+00, 1.44405869e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.69110924e-03, 5.98268680e-03, 1.30418562e-03, 1.42421617e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 3.50262478e-03, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 8.85388496e-05, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.48415115e-05,\n",
              "       0.00000000e+00, 1.44455710e-03, 0.00000000e+00, 1.11169985e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.75511962e-03,\n",
              "       0.00000000e+00, 1.03241110e-03, 1.15259184e-03, 8.36928433e-05,\n",
              "       8.93665488e-05, 8.19296124e-04, 1.00559874e-03, 0.00000000e+00,\n",
              "       1.95347125e-03, 1.33638924e-03, 4.37852899e-04, 0.00000000e+00,\n",
              "       1.70729734e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       9.55351189e-04, 9.21724270e-04, 0.00000000e+00, 1.48384244e-03,\n",
              "       6.47999447e-04, 0.00000000e+00, 4.13183020e-02, 1.23496754e-03,\n",
              "       1.24663349e-02, 0.00000000e+00, 1.55591735e-02, 0.00000000e+00,\n",
              "       0.00000000e+00, 1.05613500e-02, 0.00000000e+00, 9.24980347e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 4.93956002e-03, 0.00000000e+00,\n",
              "       4.80992149e-03, 6.04115530e-03, 3.62760292e-03, 9.25010856e-03,\n",
              "       0.00000000e+00, 1.09865808e-02, 6.70639148e-04, 0.00000000e+00,\n",
              "       2.19526185e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 2.20938022e-03, 0.00000000e+00, 6.73951887e-04,\n",
              "       8.86445281e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.10208113e-03, 2.51092270e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 2.95311288e-03, 3.42808292e-03,\n",
              "       0.00000000e+00, 1.71957319e-04, 1.09740477e-03, 8.57604183e-04,\n",
              "       0.00000000e+00, 0.00000000e+00, 5.50189037e-03, 3.65606739e-04,\n",
              "       0.00000000e+00, 4.52716218e-03, 0.00000000e+00, 5.38691357e-03,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.68369012e-03, 0.00000000e+00, 3.83613461e-05, 2.22060440e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6aqtSxMvhKC",
        "colab_type": "code",
        "outputId": "74fc67ec-b468-462c-e7db-6f34980c8bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        " sorted(zip(rank_features, data.columns), reverse=True)[:10]\n",
        " #ATTENZIONE HA SENSO SOLO SE NON SI FA PCA"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.041318302018261664, 'TEXTURE_NGTDM_ET_T1Gd_Coarseness'),\n",
              " (0.03400465904874065, 'VOLUME_ET_OVER_WT'),\n",
              " (0.025334093972020345, 'TEXTURE_GLCM_ET_T2_SumAverage'),\n",
              " (0.02512868756014921, 'TEXTURE_GLSZM_ET_T1Gd_ZSV'),\n",
              " (0.023453617320808272, 'TEXTURE_GLSZM_ET_FLAIR_ZSV'),\n",
              " (0.018844483106024136, 'TEXTURE_GLSZM_ET_T2_ZSV'),\n",
              " (0.018735550548136387, 'TEXTURE_GLRLM_ET_T2_RLV'),\n",
              " (0.01712798594740268, 'TEXTURE_GLRLM_ET_T2_GLN'),\n",
              " (0.016689808795072394, 'TEXTURE_GLRLM_ET_T1_GLV'),\n",
              " (0.016297975692483625, 'TEXTURE_GLCM_ET_T2_AutoCorrelation')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KBcqHaxUD7",
        "colab_type": "code",
        "outputId": "4623fd64-4c70-4544-fed8-d885ec39f319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "D"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_est_1': Pipeline(memory=None,\n",
              "          steps=[('scaler',\n",
              "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                 ('clf',\n",
              "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                         class_weight='balanced',\n",
              "                                         criterion='entropy', max_depth=10,\n",
              "                                         max_features='auto',\n",
              "                                         max_leaf_nodes=None, max_samples=None,\n",
              "                                         min_impurity_decrease=0.0,\n",
              "                                         min_impurity_split=None,\n",
              "                                         min_samples_leaf=2, min_samples_split=5,\n",
              "                                         min_weight_fraction_leaf=0.0,\n",
              "                                         n_estimators=150, n_jobs=None,\n",
              "                                         oob_score=False, random_state=503,\n",
              "                                         verbose=0, warm_start=False))],\n",
              "          verbose=False), 'best_est_2': Pipeline(memory=None,\n",
              "          steps=[('scaler',\n",
              "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                 ('clf',\n",
              "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                         class_weight=None, criterion='gini',\n",
              "                                         max_depth=10, max_features='auto',\n",
              "                                         max_leaf_nodes=None, max_samples=None,\n",
              "                                         min_impurity_decrease=0.0,\n",
              "                                         min_impurity_split=None,\n",
              "                                         min_samples_leaf=2, min_samples_split=2,\n",
              "                                         min_weight_fraction_leaf=0.0,\n",
              "                                         n_estimators=150, n_jobs=None,\n",
              "                                         oob_score=False, random_state=503,\n",
              "                                         verbose=0, warm_start=False))],\n",
              "          verbose=False), 'best_est_3': Pipeline(memory=None,\n",
              "          steps=[('scaler',\n",
              "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                 ('clf',\n",
              "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                         class_weight='balanced',\n",
              "                                         criterion='gini', max_depth=10,\n",
              "                                         max_features='auto',\n",
              "                                         max_leaf_nodes=None, max_samples=None,\n",
              "                                         min_impurity_decrease=0.0,\n",
              "                                         min_impurity_split=None,\n",
              "                                         min_samples_leaf=2, min_samples_split=2,\n",
              "                                         min_weight_fraction_leaf=0.0,\n",
              "                                         n_estimators=100, n_jobs=None,\n",
              "                                         oob_score=False, random_state=503,\n",
              "                                         verbose=0, warm_start=False))],\n",
              "          verbose=False)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbgrsCxZpo54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_est_1 = D['best_est_1']\n",
        "best_est_2 = D['best_est_2']\n",
        "best_est_3 = D['best_est_3']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5PqrmQup0Ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank_feat_1 = best_est_1.named_steps[\"clf\"].feature_importances_\n",
        "rank_feat_2 = best_est_2.named_steps[\"clf\"].feature_importances_\n",
        "rank_feat_3 = best_est_3.named_steps[\"clf\"].feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMThq-IDqBCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6e7b2a43-5db5-4ec6-ff8d-b32c9abef586"
      },
      "source": [
        " sorted(zip(rank_feat_1, data.columns), reverse=True)[:10]\n",
        " #ATTENZIONE HA SENSO SOLO SE NON SI FA PCA"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.026342484487602548, 'TEXTURE_GLSZM_ET_T1Gd_GLV'),\n",
              " (0.023560283277314246, 'TEXTURE_NGTDM_ET_T1Gd_Strength'),\n",
              " (0.02340422627019176, 'TEXTURE_GLRLM_ET_T2_LRLGE'),\n",
              " (0.023216571903246903, 'TEXTURE_NGTDM_ET_T1Gd_Coarseness'),\n",
              " (0.022302888335505158, 'TEXTURE_GLSZM_ET_T1Gd_ZSV'),\n",
              " (0.019226726224801843, 'TEXTURE_NGTDM_ET_T1Gd_Busyness'),\n",
              " (0.01790212923825498, 'TEXTURE_GLSZM_ET_T2_ZSV'),\n",
              " (0.017662301607302252, 'VOLUME_ET_OVER_WT'),\n",
              " (0.016624440044161855, 'TEXTURE_GLSZM_ET_FLAIR_ZSV'),\n",
              " (0.014925600570414563, 'TEXTURE_GLRLM_ET_FLAIR_LRLGE')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3tneOros_hR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "78360b55-4edc-41d8-a45a-324ac0a33231"
      },
      "source": [
        " sorted(zip(rank_feat_2, data.columns), reverse=True)[:10]\n",
        " #ATTENZIONE HA SENSO SOLO SE NON SI FA PCA"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.03056674498747392, 'TEXTURE_GLSZM_ET_T1Gd_GLV'),\n",
              " (0.02972821812812527, 'TEXTURE_GLSZM_ET_T1Gd_LZE'),\n",
              " (0.025991307811728384, 'TEXTURE_GLSZM_ET_T2_ZSV'),\n",
              " (0.022741957116920525, 'VOLUME_ET_OVER_WT'),\n",
              " (0.017425451663672476, 'TEXTURE_NGTDM_ET_T1Gd_Coarseness'),\n",
              " (0.01566934815834554, 'VOLUME_NET_over_TC'),\n",
              " (0.01429519000053494, 'TEXTURE_GLSZM_ET_T1_SZE'),\n",
              " (0.01392695433332909, 'TEXTURE_GLSZM_ET_T1_SZLGE'),\n",
              " (0.013708667058242958, 'TEXTURE_GLSZM_ET_FLAIR_ZSV'),\n",
              " (0.012092442821676106, 'VOLUME_ET_OVER_BRAIN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pul74TketATX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "45e3cd54-1db2-401a-ab8b-d1786d008c47"
      },
      "source": [
        " sorted(zip(rank_feat_3, data.columns), reverse=True)[:10]\n",
        " #ATTENZIONE HA SENSO SOLO SE NON SI FA PCA"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.041318302018261664, 'TEXTURE_NGTDM_ET_T1Gd_Coarseness'),\n",
              " (0.03400465904874065, 'VOLUME_ET_OVER_WT'),\n",
              " (0.025334093972020345, 'TEXTURE_GLCM_ET_T2_SumAverage'),\n",
              " (0.02512868756014921, 'TEXTURE_GLSZM_ET_T1Gd_ZSV'),\n",
              " (0.023453617320808272, 'TEXTURE_GLSZM_ET_FLAIR_ZSV'),\n",
              " (0.018844483106024136, 'TEXTURE_GLSZM_ET_T2_ZSV'),\n",
              " (0.018735550548136387, 'TEXTURE_GLRLM_ET_T2_RLV'),\n",
              " (0.01712798594740268, 'TEXTURE_GLRLM_ET_T2_GLN'),\n",
              " (0.016689808795072394, 'TEXTURE_GLRLM_ET_T1_GLV'),\n",
              " (0.016297975692483625, 'TEXTURE_GLCM_ET_T2_AutoCorrelation')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXkErgXj3VRa",
        "colab_type": "text"
      },
      "source": [
        "#SICCOME OTTENGO 3 SET DI BEST HP COME POSSO OTTENERE UN SOLO CLASSIFICATORE, PROVA MAJOR VOTING RULE TRA I 3 CLF, PER POI FARE CV E DARE STIMA PRESTAZIONI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_5hJb3d8jGX",
        "colab_type": "text"
      },
      "source": [
        "##E' UNA CAZZATA PERCHE COMUNQUE DOVREI VALUTARE I DIVERSI CLF SUGLI STESSI PATTERN, INTRODUCO UN BIAS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fD93iGI3mQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h7Et6Qv30Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = best_est_1\n",
        "clf2 = best_est_2\n",
        "clf3 = best_est_3\n",
        "\n",
        "eclf1 = VotingClassifier(estimators=[\n",
        "        ('clf1', clf1), ('clf2', clf2), ('clf3', clf3)], voting='soft')\n",
        "eclf1 = eclf1.fit(data, labels_encoded)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UUqVdIy41km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a625f9f0-e878-4692-edd1-f2f852ccaa83"
      },
      "source": [
        "cross_val_score(eclf1, data, labels_encoded, scoring='accuracy', cv=5)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8       , 0.86206897, 0.93103448, 0.89655172, 0.89655172])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwvHrkgB4h5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
        "               eclf1.named_estimators_['lr'].predict(X))\n",
        "\n",
        "eclf2 = VotingClassifier(estimators=[\n",
        "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "        voting='soft')\n",
        "eclf2 = eclf2.fit(X, y)\n",
        "print(eclf2.predict(X))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6J3anCRcVlg",
        "colab_type": "code",
        "outputId": "7ca2534f-b77a-4749-8822-7000d241efbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "for i in range(1, 6):\n",
        "\n",
        "    #Train test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(public_data, public_labels, test_size=0.3, \n",
        "    stratify=public_labels, random_state=i*500)\n",
        "\n",
        "    #Vettorizzare i label\n",
        "    train_labels_encoded = encoder.fit_transform(y_train)\n",
        "    test_labels_encoded = encoder.transform(y_test)\n",
        "\n",
        "    #RandomForestClassifier\n",
        "    steps = [('scaler', StandardScaler()), ('red_dim', PCA()), ('clf', RandomForestClassifier(random_state=i*503))]\n",
        "\n",
        "    pipeline = Pipeline(steps)\n",
        "\n",
        "    parameteres = [{'scaler':scalers_to_test, 'red_dim':[PCA(random_state=42)], 'red_dim__n_components':list(n_features_to_test),\n",
        "                    'red_dim__whiten':[False, True], \n",
        "                    'clf__n_estimators':list(n_tree), 'clf__criterion':['gini', 'entropy'], \n",
        "                    'clf__max_depth':depth, 'clf__min_samples_split':[2, 5, 10], \n",
        "                    'clf__min_samples_leaf':[1, 2, 4], 'clf__class_weight':[None, 'balanced']}]\n",
        "\n",
        "    grid = GridSearchCV(pipeline, param_grid=parameteres, cv=3, n_jobs=-1, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "     grid.fit(X_train, y_train)\n",
        "\n",
        "    score_train = grid.score(X_train, y_train)\n",
        "    score_test = grid.score(X_test, y_test)\n",
        "    best_p = grid.best_params_\n",
        "\n",
        "    bp = pd.DataFrame(best_p, index=[i])\n",
        "    bp['accuracy_train'] = score_train\n",
        "    bp['accuracy_test'] = score_test\n",
        "    bp['random_state'] = i*500\n",
        "    bp['random_state_pca'] = i*42\n",
        "    bp['random_state_clf'] = i*503\n",
        "\n",
        "    df = df.append(bp, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-936043f88c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     X_train, X_test, y_train, y_test = train_test_split(public_data, public_labels, test_size=0.3, \n\u001b[0m\u001b[1;32m     11\u001b[0m     stratify=public_labels, random_state=i*500)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'public_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYtNggBRaf2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ROe5ga1fue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D={i:0}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dDNMU1z1jJP",
        "colab_type": "code",
        "outputId": "6e9493a8-4eb9-440f-974c-641e89a9c1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvrS2Iqw1j__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c33ddd64-38e0-4687-e51e-89fb2c697e63"
      },
      "source": [
        "GSCV.cv_results_"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.04292591, 0.15979902, 0.28904231, 0.42704121, 0.03603745,\n",
              "        0.14704879, 0.29131174, 0.42921432, 0.03875256, 0.15052414,\n",
              "        0.28611469, 0.4364055 , 0.03680285, 0.15737081, 0.28341047,\n",
              "        0.41951609, 0.04110026, 0.14520152, 0.2877512 , 0.43643975,\n",
              "        0.03826706, 0.1525561 , 0.28027264, 0.42455276, 0.03693469,\n",
              "        0.14523554, 0.2879293 , 0.42229978, 0.03653971, 0.14446545,\n",
              "        0.28954506, 0.42053429, 0.04056875, 0.16319013, 0.31778296,\n",
              "        0.47783176, 0.04572646, 0.16461666, 0.31940985, 0.48252185,\n",
              "        0.04021899, 0.16200439, 0.31158249, 0.46601915, 0.04007824,\n",
              "        0.15897473, 0.30812319, 0.46444782, 0.04063058, 0.16757449,\n",
              "        0.32255816, 0.48391596, 0.04173533, 0.16349562, 0.32099279,\n",
              "        0.47366333, 0.04209916, 0.16413776, 0.30816483, 0.46665414,\n",
              "        0.03943976, 0.1595428 , 0.33147613, 0.46747883, 0.03749824,\n",
              "        0.14693483, 0.27852821, 0.4263742 , 0.03794654, 0.14843059,\n",
              "        0.28074233, 0.42122142, 0.03908022, 0.14497304, 0.28148254,\n",
              "        0.41844328, 0.0364569 , 0.14536277, 0.27570923, 0.41672508,\n",
              "        0.03934145, 0.15002489, 0.28960601, 0.42366529, 0.03924394,\n",
              "        0.14805698, 0.2901926 , 0.42902708, 0.03728342, 0.14103317,\n",
              "        0.28190947, 0.41161998, 0.03711772, 0.14918224, 0.28000975,\n",
              "        0.42572832, 0.04191828, 0.17080188, 0.32768067, 0.4928751 ,\n",
              "        0.04124141, 0.16917928, 0.33901683, 0.49137894, 0.04441969,\n",
              "        0.16122142, 0.31594992, 0.46889011, 0.04267025, 0.16381113,\n",
              "        0.31519659, 0.47679257, 0.04403321, 0.16847173, 0.33080236,\n",
              "        0.49782054, 0.04121304, 0.16879781, 0.33567882, 0.49179006,\n",
              "        0.04170068, 0.16409206, 0.3241992 , 0.48094765, 0.04098288,\n",
              "        0.16780957, 0.31527289, 0.3799564 ]),\n",
              " 'mean_score_time': array([0.01402855, 0.02848911, 0.04530787, 0.06618921, 0.01223183,\n",
              "        0.02745907, 0.04563904, 0.06898276, 0.01270882, 0.02848363,\n",
              "        0.04644847, 0.06447562, 0.0122691 , 0.02824577, 0.04484232,\n",
              "        0.06659897, 0.01253406, 0.02657731, 0.05142379, 0.06589643,\n",
              "        0.01312685, 0.02798676, 0.04571136, 0.07252224, 0.01259176,\n",
              "        0.02843769, 0.04632926, 0.06515002, 0.01258858, 0.02784308,\n",
              "        0.05240162, 0.06525604, 0.01265923, 0.02669907, 0.04698483,\n",
              "        0.06356017, 0.0131522 , 0.02657851, 0.0489351 , 0.06606452,\n",
              "        0.01263189, 0.02785428, 0.04509226, 0.06764174, 0.01266352,\n",
              "        0.02706234, 0.0452013 , 0.06904157, 0.01242526, 0.02760196,\n",
              "        0.04475602, 0.06348999, 0.01264882, 0.02713474, 0.04449677,\n",
              "        0.06502358, 0.01280324, 0.02622581, 0.0468146 , 0.06612039,\n",
              "        0.01257475, 0.02721834, 0.04971123, 0.06334337, 0.01301718,\n",
              "        0.02660489, 0.04464984, 0.0658466 , 0.0127422 , 0.0271244 ,\n",
              "        0.0446771 , 0.064346  , 0.01263706, 0.02610437, 0.04266842,\n",
              "        0.06560691, 0.01211691, 0.02672243, 0.04400643, 0.06595516,\n",
              "        0.01292888, 0.02679698, 0.04641501, 0.06420151, 0.01284552,\n",
              "        0.03195294, 0.04494635, 0.06377308, 0.01292761, 0.0268019 ,\n",
              "        0.04505952, 0.06506753, 0.01211818, 0.02754021, 0.04462155,\n",
              "        0.06615202, 0.01562651, 0.02716629, 0.04583637, 0.06538669,\n",
              "        0.01207463, 0.02655991, 0.04580053, 0.06358345, 0.01201804,\n",
              "        0.02709023, 0.04402614, 0.06379358, 0.01258198, 0.02650881,\n",
              "        0.0466698 , 0.06119784, 0.0131251 , 0.0275561 , 0.04542184,\n",
              "        0.06522377, 0.01252023, 0.0269084 , 0.0442334 , 0.06245812,\n",
              "        0.01304571, 0.02695775, 0.04826689, 0.06798967, 0.01265502,\n",
              "        0.02751724, 0.0466876 , 0.04267279]),\n",
              " 'mean_test_accuracy': array([0.90782828, 0.86742424, 0.85700758, 0.87752525, 0.90782828,\n",
              "        0.85732323, 0.85700758, 0.88794192, 0.84659091, 0.81628788,\n",
              "        0.86742424, 0.8677399 , 0.84659091, 0.81628788, 0.86742424,\n",
              "        0.8677399 , 0.90782828, 0.86742424, 0.85700758, 0.87752525,\n",
              "        0.90782828, 0.85732323, 0.85700758, 0.88794192, 0.84659091,\n",
              "        0.81628788, 0.86742424, 0.8677399 , 0.84659091, 0.81628788,\n",
              "        0.86742424, 0.8677399 , 0.84722222, 0.86742424, 0.86742424,\n",
              "        0.88794192, 0.85732323, 0.86742424, 0.85700758, 0.88794192,\n",
              "        0.82607323, 0.82638889, 0.85700758, 0.86742424, 0.82607323,\n",
              "        0.82638889, 0.85700758, 0.86742424, 0.84722222, 0.86742424,\n",
              "        0.86742424, 0.88794192, 0.85732323, 0.86742424, 0.85700758,\n",
              "        0.88794192, 0.82607323, 0.82638889, 0.85700758, 0.86742424,\n",
              "        0.82607323, 0.82638889, 0.85700758, 0.86742424, 0.85700758,\n",
              "        0.88825758, 0.87752525, 0.88794192, 0.85700758, 0.89804293,\n",
              "        0.86742424, 0.88794192, 0.88794192, 0.84690657, 0.85700758,\n",
              "        0.85700758, 0.88794192, 0.84690657, 0.85700758, 0.85700758,\n",
              "        0.85700758, 0.88825758, 0.87752525, 0.88794192, 0.85700758,\n",
              "        0.89804293, 0.86742424, 0.88794192, 0.88794192, 0.84690657,\n",
              "        0.85700758, 0.85700758, 0.88794192, 0.84690657, 0.85700758,\n",
              "        0.85700758, 0.8364899 , 0.84690657, 0.87752525, 0.88762626,\n",
              "        0.8364899 , 0.84690657, 0.87752525, 0.88762626, 0.81597222,\n",
              "        0.83680556, 0.85732323, 0.86710859, 0.81597222, 0.83680556,\n",
              "        0.85732323, 0.86710859, 0.8364899 , 0.84690657, 0.87752525,\n",
              "        0.88762626, 0.8364899 , 0.84690657, 0.87752525, 0.88762626,\n",
              "        0.81597222, 0.83680556, 0.85732323, 0.86710859, 0.81597222,\n",
              "        0.83680556, 0.85732323, 0.86710859]),\n",
              " 'mean_test_roc_auc': array([0.93040184, 0.93096179, 0.9513834 , 0.95862978, 0.93267457,\n",
              "        0.93751647, 0.95428195, 0.96014493, 0.92364954, 0.93517787,\n",
              "        0.9527668 , 0.96317523, 0.92364954, 0.93517787, 0.9527668 ,\n",
              "        0.96317523, 0.93040184, 0.93096179, 0.9513834 , 0.95862978,\n",
              "        0.93267457, 0.93751647, 0.95428195, 0.96014493, 0.92364954,\n",
              "        0.93517787, 0.9527668 , 0.96317523, 0.92364954, 0.93517787,\n",
              "        0.9527668 , 0.96317523, 0.90181159, 0.94331357, 0.95359025,\n",
              "        0.95586298, 0.90688406, 0.94104084, 0.95283267, 0.9588274 ,\n",
              "        0.89980237, 0.94242424, 0.95428195, 0.95724638, 0.89980237,\n",
              "        0.94242424, 0.95428195, 0.95724638, 0.90181159, 0.94331357,\n",
              "        0.95359025, 0.95586298, 0.90688406, 0.94104084, 0.95283267,\n",
              "        0.9588274 , 0.89980237, 0.94242424, 0.95428195, 0.95724638,\n",
              "        0.89980237, 0.94242424, 0.95428195, 0.95724638, 0.93083004,\n",
              "        0.95744401, 0.96613966, 0.96337286, 0.94025033, 0.95895916,\n",
              "        0.96324111, 0.96192358, 0.94749671, 0.96034256, 0.95724638,\n",
              "        0.95876153, 0.94749671, 0.96034256, 0.95724638, 0.95876153,\n",
              "        0.93083004, 0.95744401, 0.96613966, 0.96337286, 0.94025033,\n",
              "        0.95895916, 0.96324111, 0.96192358, 0.94749671, 0.96034256,\n",
              "        0.95724638, 0.95876153, 0.94749671, 0.96034256, 0.95724638,\n",
              "        0.95876153, 0.89140316, 0.9384058 , 0.95428195, 0.9513834 ,\n",
              "        0.89720026, 0.94130435, 0.94841897, 0.94993412, 0.90401845,\n",
              "        0.95144928, 0.95876153, 0.95737813, 0.90401845, 0.95144928,\n",
              "        0.95876153, 0.95737813, 0.89140316, 0.9384058 , 0.95428195,\n",
              "        0.9513834 , 0.89720026, 0.94130435, 0.94841897, 0.94993412,\n",
              "        0.90401845, 0.95144928, 0.95876153, 0.95737813, 0.90401845,\n",
              "        0.95144928, 0.95876153, 0.95737813]),\n",
              " 'param_clf__class_weight': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, 'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
              "                    'balanced', 'balanced', 'balanced', 'balanced'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
              "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, None, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    None, None, None, None, None, None, None, None, None,\n",
              "                    None, None, None, None, None, None, None],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__min_samples_leaf': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4,\n",
              "                    4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
              "                    4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4,\n",
              "                    4, 4],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__min_samples_split': masked_array(data=[2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5,\n",
              "                    5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2,\n",
              "                    2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2,\n",
              "                    5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5,\n",
              "                    5, 5],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_clf__n_estimators': masked_array(data=[10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150, 10, 50, 100, 150,\n",
              "                    10, 50, 100, 150, 10, 50, 100, 150],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_scaler': masked_array(data=[StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
              "                    StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': None,\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'gini',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': 10,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 2,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 2,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 10,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 50,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 100,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
              "  {'clf__class_weight': 'balanced',\n",
              "   'clf__criterion': 'entropy',\n",
              "   'clf__max_depth': None,\n",
              "   'clf__min_samples_leaf': 4,\n",
              "   'clf__min_samples_split': 5,\n",
              "   'clf__n_estimators': 150,\n",
              "   'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}],\n",
              " 'rank_test_accuracy': array([  1,  39,  69,  27,   1,  61,  69,   9, 101, 121,  39,  35, 101,\n",
              "        121,  39,  35,   1,  39,  69,  27,   1,  61,  69,   9, 101, 121,\n",
              "         39,  35, 101, 121,  39,  35,  91,  39,  39,   9,  61,  39,  69,\n",
              "          9, 117, 113,  69,  39, 117, 113,  69,  39,  91,  39,  39,   9,\n",
              "         61,  39,  69,   9, 117, 113,  69,  39, 117, 113,  69,  39,  69,\n",
              "          7,  27,   9,  69,   5,  39,   9,   9,  93,  69,  69,   9,  93,\n",
              "         69,  69,  69,   7,  27,   9,  69,   5,  39,   9,   9,  93,  69,\n",
              "         69,   9,  93,  69,  69, 109,  97,  27,  23, 109,  97,  27,  23,\n",
              "        125, 105,  61,  57, 125, 105,  61,  57, 109,  97,  27,  23, 109,\n",
              "         97,  27,  23, 125, 105,  61,  57, 125, 105,  61,  57], dtype=int32),\n",
              " 'rank_test_roc_auc': array([107, 103,  69,  31, 101,  95,  49,  17, 109,  97,  61,   7, 109,\n",
              "         97,  61,   7, 107, 103,  69,  31, 101,  95,  49,  17, 109,  97,\n",
              "         61,   7, 109,  97,  61,   7, 119,  81,  57,  47, 113,  89,  59,\n",
              "         21, 121,  83,  53,  39, 121,  83,  53,  39, 119,  81,  57,  47,\n",
              "        113,  89,  59,  21, 121,  83,  53,  39, 121,  83,  53,  39, 105,\n",
              "         33,   1,   3,  91,  19,   5,  11,  77,  13,  39,  23,  77,  13,\n",
              "         39,  23, 105,  33,   1,   3,  91,  19,   5,  11,  77,  13,  39,\n",
              "         23,  77,  13,  39,  23, 127,  93,  49,  69, 125,  87,  75,  73,\n",
              "        115,  65,  23,  35, 115,  65,  23,  35, 127,  93,  49,  69, 125,\n",
              "         87,  75,  73, 115,  65,  23,  35, 115,  65,  23,  35], dtype=int32),\n",
              " 'split0_test_accuracy': array([0.93939394, 0.84848485, 0.87878788, 0.87878788, 0.93939394,\n",
              "        0.81818182, 0.87878788, 0.87878788, 0.87878788, 0.78787879,\n",
              "        0.87878788, 0.84848485, 0.87878788, 0.78787879, 0.87878788,\n",
              "        0.84848485, 0.93939394, 0.84848485, 0.87878788, 0.87878788,\n",
              "        0.93939394, 0.81818182, 0.87878788, 0.87878788, 0.87878788,\n",
              "        0.78787879, 0.87878788, 0.84848485, 0.87878788, 0.78787879,\n",
              "        0.87878788, 0.84848485, 0.81818182, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.84848485, 0.84848485, 0.87878788, 0.87878788,\n",
              "        0.81818182, 0.78787879, 0.87878788, 0.87878788, 0.81818182,\n",
              "        0.78787879, 0.87878788, 0.87878788, 0.81818182, 0.84848485,\n",
              "        0.87878788, 0.87878788, 0.84848485, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.81818182, 0.78787879, 0.87878788, 0.87878788,\n",
              "        0.81818182, 0.78787879, 0.87878788, 0.87878788, 0.87878788,\n",
              "        0.84848485, 0.90909091, 0.84848485, 0.87878788, 0.87878788,\n",
              "        0.87878788, 0.84848485, 0.87878788, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.87878788, 0.84848485, 0.84848485, 0.84848485,\n",
              "        0.87878788, 0.84848485, 0.90909091, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.87878788, 0.84848485, 0.87878788, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.87878788, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.78787879, 0.87878788, 0.87878788,\n",
              "        0.84848485, 0.78787879, 0.87878788, 0.87878788, 0.81818182,\n",
              "        0.81818182, 0.84848485, 0.84848485, 0.81818182, 0.81818182,\n",
              "        0.84848485, 0.84848485, 0.84848485, 0.78787879, 0.87878788,\n",
              "        0.87878788, 0.84848485, 0.78787879, 0.87878788, 0.87878788,\n",
              "        0.81818182, 0.81818182, 0.84848485, 0.84848485, 0.81818182,\n",
              "        0.81818182, 0.84848485, 0.84848485]),\n",
              " 'split0_test_roc_auc': array([0.92826087, 0.9326087 , 0.95217391, 0.96956522, 0.92826087,\n",
              "        0.93478261, 0.95652174, 0.96521739, 0.90869565, 0.93043478,\n",
              "        0.95652174, 0.95652174, 0.90869565, 0.93043478, 0.95652174,\n",
              "        0.95652174, 0.92826087, 0.9326087 , 0.95217391, 0.96956522,\n",
              "        0.92826087, 0.93478261, 0.95652174, 0.96521739, 0.90869565,\n",
              "        0.93043478, 0.95652174, 0.95652174, 0.90869565, 0.93043478,\n",
              "        0.95652174, 0.95652174, 0.88043478, 0.93913043, 0.94782609,\n",
              "        0.95217391, 0.88478261, 0.94347826, 0.94782609, 0.95217391,\n",
              "        0.86086957, 0.92608696, 0.94782609, 0.94782609, 0.86086957,\n",
              "        0.92608696, 0.94782609, 0.94782609, 0.88043478, 0.93913043,\n",
              "        0.94782609, 0.95217391, 0.88478261, 0.94347826, 0.94782609,\n",
              "        0.95217391, 0.86086957, 0.92608696, 0.94782609, 0.94782609,\n",
              "        0.86086957, 0.92608696, 0.94782609, 0.94782609, 0.93913043,\n",
              "        0.94782609, 0.96086957, 0.94782609, 0.95      , 0.94782609,\n",
              "        0.96086957, 0.94782609, 0.95      , 0.95652174, 0.95217391,\n",
              "        0.95217391, 0.95      , 0.95652174, 0.95217391, 0.95217391,\n",
              "        0.93913043, 0.94782609, 0.96086957, 0.94782609, 0.95      ,\n",
              "        0.94782609, 0.96086957, 0.94782609, 0.95      , 0.95652174,\n",
              "        0.95217391, 0.95217391, 0.95      , 0.95652174, 0.95217391,\n",
              "        0.95217391, 0.94130435, 0.93478261, 0.95652174, 0.94782609,\n",
              "        0.94565217, 0.93913043, 0.94782609, 0.94347826, 0.90434783,\n",
              "        0.92608696, 0.95217391, 0.94782609, 0.90434783, 0.92608696,\n",
              "        0.95217391, 0.94782609, 0.94130435, 0.93478261, 0.95652174,\n",
              "        0.94782609, 0.94565217, 0.93913043, 0.94782609, 0.94347826,\n",
              "        0.90434783, 0.92608696, 0.95217391, 0.94782609, 0.90434783,\n",
              "        0.92608696, 0.95217391, 0.94782609]),\n",
              " 'split1_test_accuracy': array([0.90909091, 0.87878788, 0.84848485, 0.87878788, 0.90909091,\n",
              "        0.87878788, 0.84848485, 0.87878788, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.84848485, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.90909091, 0.87878788, 0.84848485, 0.87878788,\n",
              "        0.90909091, 0.87878788, 0.84848485, 0.87878788, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.84848485, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.84848485, 0.87878788, 0.84848485,\n",
              "        0.87878788, 0.84848485, 0.87878788, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.87878788, 0.84848485, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.84848485, 0.84848485, 0.84848485, 0.87878788,\n",
              "        0.84848485, 0.87878788, 0.84848485, 0.87878788, 0.84848485,\n",
              "        0.87878788, 0.87878788, 0.87878788, 0.84848485, 0.84848485,\n",
              "        0.87878788, 0.87878788, 0.84848485, 0.84848485, 0.84848485,\n",
              "        0.87878788, 0.84848485, 0.90909091, 0.84848485, 0.90909091,\n",
              "        0.84848485, 0.90909091, 0.87878788, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.87878788, 0.84848485, 0.87878788, 0.87878788,\n",
              "        0.84848485, 0.87878788, 0.84848485, 0.90909091, 0.84848485,\n",
              "        0.90909091, 0.84848485, 0.90909091, 0.87878788, 0.84848485,\n",
              "        0.87878788, 0.87878788, 0.87878788, 0.84848485, 0.87878788,\n",
              "        0.87878788, 0.84848485, 0.90909091, 0.87878788, 0.90909091,\n",
              "        0.84848485, 0.90909091, 0.87878788, 0.90909091, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.90909091, 0.84848485, 0.84848485,\n",
              "        0.84848485, 0.90909091, 0.84848485, 0.90909091, 0.87878788,\n",
              "        0.90909091, 0.84848485, 0.90909091, 0.87878788, 0.90909091,\n",
              "        0.84848485, 0.84848485, 0.84848485, 0.90909091, 0.84848485,\n",
              "        0.84848485, 0.84848485, 0.90909091]),\n",
              " 'split1_test_roc_auc': array([0.91521739, 0.92391304, 0.95652174, 0.96086957, 0.91521739,\n",
              "        0.93913043, 0.96086957, 0.96521739, 0.93043478, 0.94782609,\n",
              "        0.96086957, 0.97391304, 0.93043478, 0.94782609, 0.96086957,\n",
              "        0.97391304, 0.91521739, 0.92391304, 0.95652174, 0.96086957,\n",
              "        0.91521739, 0.93913043, 0.96086957, 0.96521739, 0.93043478,\n",
              "        0.94782609, 0.96086957, 0.97391304, 0.93043478, 0.94782609,\n",
              "        0.96086957, 0.97391304, 0.9       , 0.95217391, 0.96521739,\n",
              "        0.96086957, 0.91086957, 0.94782609, 0.96521739, 0.96521739,\n",
              "        0.95217391, 0.97391304, 0.96956522, 0.97391304, 0.95217391,\n",
              "        0.97391304, 0.96956522, 0.97391304, 0.9       , 0.95217391,\n",
              "        0.96521739, 0.96086957, 0.91086957, 0.94782609, 0.96521739,\n",
              "        0.96521739, 0.95217391, 0.97391304, 0.96956522, 0.97391304,\n",
              "        0.95217391, 0.97391304, 0.96956522, 0.97391304, 0.92608696,\n",
              "        0.96086957, 0.97391304, 0.96956522, 0.94347826, 0.96086957,\n",
              "        0.96521739, 0.96521739, 0.96521739, 0.96086957, 0.96956522,\n",
              "        0.96956522, 0.96521739, 0.96086957, 0.96956522, 0.96956522,\n",
              "        0.92608696, 0.96086957, 0.97391304, 0.96956522, 0.94347826,\n",
              "        0.96086957, 0.96521739, 0.96521739, 0.96521739, 0.96086957,\n",
              "        0.96956522, 0.96956522, 0.96521739, 0.96086957, 0.96956522,\n",
              "        0.96956522, 0.87608696, 0.93043478, 0.96086957, 0.96086957,\n",
              "        0.88913043, 0.93478261, 0.95652174, 0.96086957, 0.93043478,\n",
              "        0.97826087, 0.96956522, 0.96521739, 0.93043478, 0.97826087,\n",
              "        0.96956522, 0.96521739, 0.87608696, 0.93043478, 0.96086957,\n",
              "        0.96086957, 0.88913043, 0.93478261, 0.95652174, 0.96086957,\n",
              "        0.93043478, 0.97826087, 0.96956522, 0.96521739, 0.93043478,\n",
              "        0.97826087, 0.96956522, 0.96521739]),\n",
              " 'split2_test_accuracy': array([0.875  , 0.875  , 0.84375, 0.875  , 0.875  , 0.875  , 0.84375,\n",
              "        0.90625, 0.8125 , 0.8125 , 0.875  , 0.90625, 0.8125 , 0.8125 ,\n",
              "        0.875  , 0.90625, 0.875  , 0.875  , 0.84375, 0.875  , 0.875  ,\n",
              "        0.875  , 0.84375, 0.90625, 0.8125 , 0.8125 , 0.875  , 0.90625,\n",
              "        0.8125 , 0.8125 , 0.875  , 0.90625, 0.875  , 0.875  , 0.875  ,\n",
              "        0.90625, 0.875  , 0.875  , 0.84375, 0.90625, 0.78125, 0.8125 ,\n",
              "        0.84375, 0.875  , 0.78125, 0.8125 , 0.84375, 0.875  , 0.875  ,\n",
              "        0.875  , 0.875  , 0.90625, 0.875  , 0.875  , 0.84375, 0.90625,\n",
              "        0.78125, 0.8125 , 0.84375, 0.875  , 0.78125, 0.8125 , 0.84375,\n",
              "        0.875  , 0.84375, 0.9375 , 0.875  , 0.90625, 0.84375, 0.90625,\n",
              "        0.875  , 0.90625, 0.90625, 0.84375, 0.84375, 0.84375, 0.90625,\n",
              "        0.84375, 0.84375, 0.84375, 0.84375, 0.9375 , 0.875  , 0.90625,\n",
              "        0.84375, 0.90625, 0.875  , 0.90625, 0.90625, 0.84375, 0.84375,\n",
              "        0.84375, 0.90625, 0.84375, 0.84375, 0.84375, 0.8125 , 0.84375,\n",
              "        0.875  , 0.875  , 0.8125 , 0.84375, 0.875  , 0.875  , 0.78125,\n",
              "        0.84375, 0.875  , 0.84375, 0.78125, 0.84375, 0.875  , 0.84375,\n",
              "        0.8125 , 0.84375, 0.875  , 0.875  , 0.8125 , 0.84375, 0.875  ,\n",
              "        0.875  , 0.78125, 0.84375, 0.875  , 0.84375, 0.78125, 0.84375,\n",
              "        0.875  , 0.84375]),\n",
              " 'split2_test_roc_auc': array([0.94772727, 0.93636364, 0.94545455, 0.94545455, 0.95454545,\n",
              "        0.93863636, 0.94545455, 0.95      , 0.93181818, 0.92727273,\n",
              "        0.94090909, 0.95909091, 0.93181818, 0.92727273, 0.94090909,\n",
              "        0.95909091, 0.94772727, 0.93636364, 0.94545455, 0.94545455,\n",
              "        0.95454545, 0.93863636, 0.94545455, 0.95      , 0.93181818,\n",
              "        0.92727273, 0.94090909, 0.95909091, 0.93181818, 0.92727273,\n",
              "        0.94090909, 0.95909091, 0.925     , 0.93863636, 0.94772727,\n",
              "        0.95454545, 0.925     , 0.93181818, 0.94545455, 0.95909091,\n",
              "        0.88636364, 0.92727273, 0.94545455, 0.95      , 0.88636364,\n",
              "        0.92727273, 0.94545455, 0.95      , 0.925     , 0.93863636,\n",
              "        0.94772727, 0.95454545, 0.925     , 0.93181818, 0.94545455,\n",
              "        0.95909091, 0.88636364, 0.92727273, 0.94545455, 0.95      ,\n",
              "        0.88636364, 0.92727273, 0.94545455, 0.95      , 0.92727273,\n",
              "        0.96363636, 0.96363636, 0.97272727, 0.92727273, 0.96818182,\n",
              "        0.96363636, 0.97272727, 0.92727273, 0.96363636, 0.95      ,\n",
              "        0.95454545, 0.92727273, 0.96363636, 0.95      , 0.95454545,\n",
              "        0.92727273, 0.96363636, 0.96363636, 0.97272727, 0.92727273,\n",
              "        0.96818182, 0.96363636, 0.97272727, 0.92727273, 0.96363636,\n",
              "        0.95      , 0.95454545, 0.92727273, 0.96363636, 0.95      ,\n",
              "        0.95454545, 0.85681818, 0.95      , 0.94545455, 0.94545455,\n",
              "        0.85681818, 0.95      , 0.94090909, 0.94545455, 0.87727273,\n",
              "        0.95      , 0.95454545, 0.95909091, 0.87727273, 0.95      ,\n",
              "        0.95454545, 0.95909091, 0.85681818, 0.95      , 0.94545455,\n",
              "        0.94545455, 0.85681818, 0.95      , 0.94090909, 0.94545455,\n",
              "        0.87727273, 0.95      , 0.95454545, 0.95909091, 0.87727273,\n",
              "        0.95      , 0.95454545, 0.95909091]),\n",
              " 'std_fit_time': array([0.00600516, 0.00533907, 0.00894167, 0.00419145, 0.00038758,\n",
              "        0.00210501, 0.0078749 , 0.00724519, 0.00104781, 0.00537151,\n",
              "        0.0043494 , 0.01354521, 0.00056547, 0.0116985 , 0.00596467,\n",
              "        0.00999507, 0.00548326, 0.00120153, 0.00428955, 0.00556373,\n",
              "        0.00082534, 0.00448438, 0.00078125, 0.0024829 , 0.00080015,\n",
              "        0.0017738 , 0.00725762, 0.00726226, 0.00071757, 0.00109407,\n",
              "        0.00548777, 0.00637396, 0.00021457, 0.00015271, 0.0051678 ,\n",
              "        0.00383335, 0.00608087, 0.00475779, 0.00220188, 0.00784231,\n",
              "        0.00053356, 0.00279919, 0.006175  , 0.00825194, 0.00026466,\n",
              "        0.00038436, 0.00244198, 0.00269751, 0.00095946, 0.00118992,\n",
              "        0.00578048, 0.01506057, 0.00082198, 0.00111965, 0.00282945,\n",
              "        0.00172565, 0.00313888, 0.0069771 , 0.003406  , 0.00812859,\n",
              "        0.00077373, 0.00220296, 0.01105096, 0.00531141, 0.00063738,\n",
              "        0.00272374, 0.00349249, 0.00633494, 0.00050412, 0.00452867,\n",
              "        0.00357568, 0.00418307, 0.00276862, 0.00384592, 0.0069911 ,\n",
              "        0.00951502, 0.00034538, 0.00174076, 0.00234994, 0.00684159,\n",
              "        0.0015262 , 0.0046166 , 0.0102231 , 0.00318145, 0.00066263,\n",
              "        0.00340529, 0.00547223, 0.00813875, 0.00052571, 0.00076336,\n",
              "        0.00543841, 0.00329611, 0.00061715, 0.00439932, 0.00802508,\n",
              "        0.00737674, 0.00074746, 0.00405548, 0.00226716, 0.0093245 ,\n",
              "        0.00045757, 0.00305266, 0.01027475, 0.01240918, 0.00618689,\n",
              "        0.00188383, 0.00375972, 0.00604952, 0.00311872, 0.00383417,\n",
              "        0.00234719, 0.00245862, 0.00189676, 0.00290218, 0.00360198,\n",
              "        0.00933422, 0.00099536, 0.00208489, 0.00830666, 0.00422738,\n",
              "        0.00255989, 0.00173731, 0.00864537, 0.00833873, 0.0006125 ,\n",
              "        0.00538904, 0.00182432, 0.08594617]),\n",
              " 'std_score_time': array([2.92488708e-03, 6.23951853e-04, 1.68207443e-03, 5.79853863e-04,\n",
              "        3.03405792e-04, 9.56209495e-04, 1.20129592e-03, 4.34986774e-03,\n",
              "        4.42183635e-04, 6.10887986e-04, 1.10625075e-03, 2.44918878e-03,\n",
              "        3.41143210e-05, 5.21763044e-04, 5.27086641e-04, 7.50430607e-04,\n",
              "        2.78983178e-04, 6.74820595e-04, 6.23435876e-03, 1.30489972e-03,\n",
              "        3.70576261e-04, 9.72864726e-04, 8.96179747e-04, 1.03291494e-02,\n",
              "        2.43775455e-04, 1.63135618e-04, 7.21326181e-04, 2.37020465e-03,\n",
              "        3.61579695e-04, 9.77597918e-04, 7.53171945e-03, 3.48841060e-03,\n",
              "        6.37537799e-05, 1.05984624e-03, 7.23515406e-04, 2.00521327e-03,\n",
              "        1.60954301e-04, 2.66572111e-04, 6.59239151e-03, 9.69880105e-04,\n",
              "        5.29296978e-04, 7.74523010e-04, 1.20880816e-03, 4.43210575e-03,\n",
              "        2.36404361e-04, 1.13302229e-03, 1.56845308e-03, 2.22948065e-03,\n",
              "        4.44010692e-04, 5.35775017e-04, 1.40244367e-03, 3.03944436e-03,\n",
              "        5.89608616e-04, 1.24313714e-03, 1.81031183e-03, 1.52256946e-03,\n",
              "        1.07153054e-04, 4.78946194e-04, 2.15169316e-03, 4.38800862e-03,\n",
              "        2.71117069e-04, 1.28984047e-03, 4.79644773e-03, 2.59881409e-03,\n",
              "        2.63043304e-04, 1.12721038e-03, 1.67641463e-03, 1.02375443e-03,\n",
              "        3.26731088e-05, 8.62969893e-04, 1.81915855e-03, 2.05194811e-03,\n",
              "        4.31892403e-05, 3.89242474e-04, 6.56193692e-05, 1.92417757e-03,\n",
              "        7.10825978e-05, 8.93926673e-04, 7.61332044e-04, 1.69798861e-03,\n",
              "        2.65309236e-04, 1.48596458e-03, 1.43932455e-03, 4.17192967e-03,\n",
              "        1.89963310e-04, 4.73346242e-03, 1.37877405e-03, 1.03779041e-03,\n",
              "        7.16638112e-05, 3.09435251e-04, 8.98250180e-04, 2.15146068e-03,\n",
              "        6.21525526e-05, 3.78620464e-04, 1.55892858e-03, 1.98217811e-03,\n",
              "        3.85076300e-03, 8.56511046e-04, 1.06541571e-03, 1.48062212e-03,\n",
              "        6.46005346e-05, 5.32143871e-04, 2.05239563e-03, 1.71093487e-03,\n",
              "        1.23982755e-05, 1.13876305e-03, 4.12568775e-04, 2.65873522e-03,\n",
              "        2.35376125e-04, 6.78094211e-04, 5.75646879e-04, 1.36212684e-03,\n",
              "        8.55641140e-05, 1.01038681e-03, 1.03060640e-03, 5.28230601e-04,\n",
              "        3.94831549e-04, 8.64724521e-04, 2.44330034e-03, 1.89404007e-03,\n",
              "        1.41551604e-03, 1.47180010e-03, 2.23486582e-03, 3.35094440e-03,\n",
              "        8.05349116e-05, 1.02260606e-03, 3.46386231e-04, 1.27815993e-02]),\n",
              " 'std_test_accuracy': array([0.02630387, 0.01348116, 0.01552183, 0.00178562, 0.02630387,\n",
              "        0.02772033, 0.01552183, 0.01294577, 0.02709503, 0.02488687,\n",
              "        0.01348116, 0.02723075, 0.02709503, 0.02488687, 0.01348116,\n",
              "        0.02723075, 0.02630387, 0.01348116, 0.01552183, 0.00178562,\n",
              "        0.02630387, 0.02772033, 0.01552183, 0.01294577, 0.02709503,\n",
              "        0.02488687, 0.01348116, 0.02723075, 0.02709503, 0.02488687,\n",
              "        0.01348116, 0.02723075, 0.0232131 , 0.01348116, 0.01348116,\n",
              "        0.01294577, 0.01249936, 0.01348116, 0.01552183, 0.01294577,\n",
              "        0.04020875, 0.0383909 , 0.01552183, 0.01348116, 0.04020875,\n",
              "        0.0383909 , 0.01552183, 0.01348116, 0.0232131 , 0.01348116,\n",
              "        0.01348116, 0.01294577, 0.01249936, 0.01348116, 0.01552183,\n",
              "        0.01294577, 0.04020875, 0.0383909 , 0.01552183, 0.01348116,\n",
              "        0.04020875, 0.0383909 , 0.01552183, 0.01348116, 0.01552183,\n",
              "        0.03695205, 0.02480667, 0.02792446, 0.01552183, 0.01366468,\n",
              "        0.01348116, 0.02792446, 0.01294577, 0.00223203, 0.01552183,\n",
              "        0.01552183, 0.01294577, 0.00223203, 0.01552183, 0.01552183,\n",
              "        0.01552183, 0.03695205, 0.02480667, 0.02792446, 0.01552183,\n",
              "        0.01366468, 0.01348116, 0.02792446, 0.01294577, 0.00223203,\n",
              "        0.01552183, 0.01552183, 0.01294577, 0.00223203, 0.01552183,\n",
              "        0.01552183, 0.01696342, 0.04953495, 0.00178562, 0.01525637,\n",
              "        0.01696342, 0.04953495, 0.00178562, 0.01525637, 0.02749294,\n",
              "        0.01331008, 0.01249936, 0.02974885, 0.02749294, 0.01331008,\n",
              "        0.01249936, 0.02974885, 0.01696342, 0.04953495, 0.00178562,\n",
              "        0.01525637, 0.01696342, 0.04953495, 0.00178562, 0.01525637,\n",
              "        0.02749294, 0.01331008, 0.01249936, 0.02974885, 0.02749294,\n",
              "        0.01331008, 0.01249936, 0.02974885]),\n",
              " 'std_test_roc_auc': array([0.01335817, 0.00521463, 0.00455261, 0.00996974, 0.01635613,\n",
              "        0.00194363, 0.00648939, 0.00717355, 0.01058907, 0.00903633,\n",
              "        0.00857048, 0.00766488, 0.01058907, 0.00903633, 0.00857048,\n",
              "        0.00766488, 0.01335817, 0.00521463, 0.00455261, 0.00996974,\n",
              "        0.01635613, 0.00194363, 0.00648939, 0.00717355, 0.01058907,\n",
              "        0.00903633, 0.00857048, 0.00766488, 0.01058907, 0.00903633,\n",
              "        0.00857048, 0.00766488, 0.01823871, 0.00626845, 0.00822173,\n",
              "        0.00367019, 0.01665879, 0.00675865, 0.00881067, 0.00532824,\n",
              "        0.03846705, 0.02227121, 0.01085018, 0.01181848, 0.03846705,\n",
              "        0.02227121, 0.01085018, 0.01181848, 0.01823871, 0.00626845,\n",
              "        0.00822173, 0.00367019, 0.01665879, 0.00675865, 0.00881067,\n",
              "        0.00532824, 0.03846705, 0.02227121, 0.01085018, 0.01181848,\n",
              "        0.03846705, 0.02227121, 0.01085018, 0.01181848, 0.0058892 ,\n",
              "        0.00689406, 0.00561147, 0.01106876, 0.00955499, 0.00841927,\n",
              "        0.00179686, 0.01042926, 0.01559165, 0.00292834, 0.00875583,\n",
              "        0.00770047, 0.01559165, 0.00292834, 0.00875583, 0.00770047,\n",
              "        0.0058892 , 0.00689406, 0.00561147, 0.01106876, 0.00955499,\n",
              "        0.00841927, 0.00179686, 0.01042926, 0.01559165, 0.00292834,\n",
              "        0.00875583, 0.00770047, 0.01559165, 0.00292834, 0.00875583,\n",
              "        0.00770047, 0.0361517 , 0.00838829, 0.00648939, 0.00677724,\n",
              "        0.0367125 , 0.00639983, 0.00638761, 0.0077745 , 0.02170457,\n",
              "        0.02132455, 0.00770047, 0.00720253, 0.02170457, 0.02132455,\n",
              "        0.00770047, 0.00720253, 0.0361517 , 0.00838829, 0.00648939,\n",
              "        0.00677724, 0.0367125 , 0.00639983, 0.00638761, 0.0077745 ,\n",
              "        0.02170457, 0.02132455, 0.00770047, 0.00720253, 0.02170457,\n",
              "        0.02132455, 0.00770047, 0.00720253])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC0l9m7jzBpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.DataFrame.from_dict(GSCV.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8RgFBOQz16S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "3a004323-93c0-4db0-a69e-367accf45c40"
      },
      "source": [
        "result"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_clf__class_weight</th>\n",
              "      <th>param_clf__criterion</th>\n",
              "      <th>param_clf__max_depth</th>\n",
              "      <th>param_clf__min_samples_leaf</th>\n",
              "      <th>param_clf__min_samples_split</th>\n",
              "      <th>param_clf__n_estimators</th>\n",
              "      <th>param_scaler</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_roc_auc</th>\n",
              "      <th>split1_test_roc_auc</th>\n",
              "      <th>split2_test_roc_auc</th>\n",
              "      <th>mean_test_roc_auc</th>\n",
              "      <th>std_test_roc_auc</th>\n",
              "      <th>rank_test_roc_auc</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>std_test_accuracy</th>\n",
              "      <th>rank_test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.042926</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>0.014029</td>\n",
              "      <td>0.002925</td>\n",
              "      <td>None</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': None, 'clf__criterion': ...</td>\n",
              "      <td>0.928261</td>\n",
              "      <td>0.915217</td>\n",
              "      <td>0.947727</td>\n",
              "      <td>0.930402</td>\n",
              "      <td>0.013358</td>\n",
              "      <td>107</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.907828</td>\n",
              "      <td>0.026304</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.159799</td>\n",
              "      <td>0.005339</td>\n",
              "      <td>0.028489</td>\n",
              "      <td>0.000624</td>\n",
              "      <td>None</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': None, 'clf__criterion': ...</td>\n",
              "      <td>0.932609</td>\n",
              "      <td>0.923913</td>\n",
              "      <td>0.936364</td>\n",
              "      <td>0.930962</td>\n",
              "      <td>0.005215</td>\n",
              "      <td>103</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.867424</td>\n",
              "      <td>0.013481</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.289042</td>\n",
              "      <td>0.008942</td>\n",
              "      <td>0.045308</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>None</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': None, 'clf__criterion': ...</td>\n",
              "      <td>0.952174</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.951383</td>\n",
              "      <td>0.004553</td>\n",
              "      <td>69</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.857008</td>\n",
              "      <td>0.015522</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.427041</td>\n",
              "      <td>0.004191</td>\n",
              "      <td>0.066189</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>None</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': None, 'clf__criterion': ...</td>\n",
              "      <td>0.969565</td>\n",
              "      <td>0.960870</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.958630</td>\n",
              "      <td>0.009970</td>\n",
              "      <td>31</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.877525</td>\n",
              "      <td>0.001786</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.036037</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>None</td>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': None, 'clf__criterion': ...</td>\n",
              "      <td>0.928261</td>\n",
              "      <td>0.915217</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.932675</td>\n",
              "      <td>0.016356</td>\n",
              "      <td>101</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.907828</td>\n",
              "      <td>0.026304</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0.480948</td>\n",
              "      <td>0.008339</td>\n",
              "      <td>0.067990</td>\n",
              "      <td>0.003351</td>\n",
              "      <td>balanced</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': 'balanced', 'clf__criter...</td>\n",
              "      <td>0.947826</td>\n",
              "      <td>0.965217</td>\n",
              "      <td>0.959091</td>\n",
              "      <td>0.957378</td>\n",
              "      <td>0.007203</td>\n",
              "      <td>35</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.867109</td>\n",
              "      <td>0.029749</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.040983</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.012655</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>balanced</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': 'balanced', 'clf__criter...</td>\n",
              "      <td>0.904348</td>\n",
              "      <td>0.930435</td>\n",
              "      <td>0.877273</td>\n",
              "      <td>0.904018</td>\n",
              "      <td>0.021705</td>\n",
              "      <td>115</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.815972</td>\n",
              "      <td>0.027493</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>0.167810</td>\n",
              "      <td>0.005389</td>\n",
              "      <td>0.027517</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>balanced</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': 'balanced', 'clf__criter...</td>\n",
              "      <td>0.926087</td>\n",
              "      <td>0.978261</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.951449</td>\n",
              "      <td>0.021325</td>\n",
              "      <td>65</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.836806</td>\n",
              "      <td>0.013310</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>0.315273</td>\n",
              "      <td>0.001824</td>\n",
              "      <td>0.046688</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>balanced</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': 'balanced', 'clf__criter...</td>\n",
              "      <td>0.952174</td>\n",
              "      <td>0.969565</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.958762</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>23</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.857323</td>\n",
              "      <td>0.012499</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>0.379956</td>\n",
              "      <td>0.085946</td>\n",
              "      <td>0.042673</td>\n",
              "      <td>0.012782</td>\n",
              "      <td>balanced</td>\n",
              "      <td>entropy</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
              "      <td>{'clf__class_weight': 'balanced', 'clf__criter...</td>\n",
              "      <td>0.947826</td>\n",
              "      <td>0.965217</td>\n",
              "      <td>0.959091</td>\n",
              "      <td>0.957378</td>\n",
              "      <td>0.007203</td>\n",
              "      <td>35</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.84375</td>\n",
              "      <td>0.867109</td>\n",
              "      <td>0.029749</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_fit_time  std_fit_time  ...  std_test_accuracy  rank_test_accuracy\n",
              "0         0.042926      0.006005  ...           0.026304                   1\n",
              "1         0.159799      0.005339  ...           0.013481                  39\n",
              "2         0.289042      0.008942  ...           0.015522                  69\n",
              "3         0.427041      0.004191  ...           0.001786                  27\n",
              "4         0.036037      0.000388  ...           0.026304                   1\n",
              "..             ...           ...  ...                ...                 ...\n",
              "123       0.480948      0.008339  ...           0.029749                  57\n",
              "124       0.040983      0.000613  ...           0.027493                 125\n",
              "125       0.167810      0.005389  ...           0.013310                 105\n",
              "126       0.315273      0.001824  ...           0.012499                  61\n",
              "127       0.379956      0.085946  ...           0.029749                  57\n",
              "\n",
              "[128 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne4HVcIfz3Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}